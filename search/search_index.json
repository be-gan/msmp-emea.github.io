{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Marketing Mix Modeling (MMM) is a powerful analytical approach that helps businesses understand the impact of marketing activities on business outcomes. By analyzing data across multiple marketing channels, MMM helps you optimize marketing spend, predict future outcomes, and make data-driven decisions. </p> <p>The <code>msmp.emea</code> R package provides a structured approach to perform MMM analysis with ease. It automates many of the key tasks required in an MMM analysis, such as data preparation, model estimation, and result interpretation.</p> <p>With <code>msmp.emea</code>, analysts can:</p> <ul> <li>Set Up Projects Easily: Automatically generate a structured project folder to keep analyses organized.</li> <li>Ingest and Clean Data: Read client data from various sources and apply essential preprocessing steps to make sure it's ready for analysis.</li> <li>Transform Data: Apply necessary transformations such as scaling, lagging, and feature engineering to prepare the data.</li> <li>Estimate Model Coefficients: Fit the MMM model to the data and extract key parameters for analysis.</li> <li>Decompose Results: Break down the contribution of each marketing channel for actionable insights.</li> <li>Calculate Response Curves: Understand diminishing returns and optimize media spend.</li> <li>Export and Save Results: Store results in structured formats for further analysis and reporting.</li> </ul> <p>This guide will walk you through the entire process of using the <code>msmp.emea</code> package to conduct MMM analysis. Whether you\u2019re new to MMM or an experienced analyst, <code>msmp.emea</code> streamlines the process and helps you focus on interpreting results and driving strategic decisions.</p>"},{"location":"advanced-tools/","title":"Advanced Tools","text":"<p>The features described in this section go beyond the core <code>msmp.emea</code> workflow. </p> <p>While they are not required for the standard analysis pipeline, they are designed to support analysts who need greater flexibility or advanced functionality when processing and modeling data. </p> <p>These tools aim to streamline common tasks, handle edge cases, and provide more control over specific steps in the modeling process, ultimately making the overall workflow more adaptable to different analytical needs.</p>"},{"location":"advanced-tools/#feature-engineering-with-ga","title":"Feature Engineering with GA","text":"<p>The <code>msmp.emea</code> package includes a function called <code>new_ga()</code> that runs a genetic algorithm (GA) to find the best parameter values for a model simulation. It works by testing many different combinations of parameters and selecting those that lead to better simulation results, based on a score defined by the user. </p> <p>The goal is to maximize this score, so the function keeps improving the parameter sets over several generations. It automatically filters out poor or invalid solutions, applies any constraints set by the user, and ensures that only simulations meeting minimum performance standards are considered. </p> <p>This makes the function a useful tool for tuning models when the best settings are not known in advance.</p> <p></p>"},{"location":"advanced-tools/#function-description","title":"Function description","text":"InitialisationInputsOutputs <p>The first time you run <code>new_ga</code>, it automatically creates a new Excel file in your project folder at \"07_ga_search_constraints/_ga_all_inputs.xlsx\". This file includes three sheets that define the full set of constraints the genetic algorithm will use to search for the optimal solution to your modeling problem.</p> Test_VariablesScoring_CriteriaSelection_Rules <p>The Test_Variables sheet controls how each raw variable from Variable.csv is used by the Genetic Algorithm (GA). Each row represents a single original variable and specifies:</p> Column Populate From / Allowed Values Orig_Variable The exact variable name as it appears in <code>Variable.csv</code>. Variable_Group Use the grouping column from <code>Variable.csv</code> to assign this variable to one of your pre-defined selection-rule groups. Include Controls GA inclusion: - <code>1</code> = force include - <code>0</code> = force exclude - <code>test</code> = let GA decide include vs. exclude VaryBy Coefficient variation across panels: - <code>None</code> = one coefficient for all panels - <code>&lt;panel_column_name&gt;</code> = separate coefficients by panel - <code>test</code> = GA chooses best approach Transform Whether to apply a transformation: - <code>Y</code> = use the <code>TransformType</code> defined in <code>Variable.csv</code> - <code>test</code> = GA will try different transformations TransformType One of: <code>lag</code>, <code>log</code>, <code>ma</code>, <code>adstockv3</code>, <code>abc</code>, <code>abcnew</code>, <code>adr</code>. Lag Two integers separated by <code>;</code> (e.g. <code>1;4</code> for lags 1\u20134). Scale (Optional) reserved for future use\u2014leave blank unless your process documentation specifies otherwise. Effective Two integers separated by <code>;</code> defining the \u201ceffective window\u201d length. Recency Two integers separated by <code>;</code> for the recency parameter. Decay Two decimals between 0 and 1 separated by <code>;</code> (e.g. <code>0.1;0.5</code>). Period Two integers separated by <code>;</code> for periodicity tuning. Window Two integers separated by <code>;</code> for the adstock or moving-average window. Length Two integers separated by <code>;</code> for adstock length. Peak Two integers separated by <code>;</code> for the ABC/ADR peak parameter. A Constant A for ABC/ADR\u2014always set to <code>1</code>. B Three integers separated by <code>;</code>, pre-populated using the IQR of the raw variable (e.g. <code>10;50;100</code>). C Two values between \u20135 and 0 separated by <code>;</code>, pre-populated with <code>-2;-0.5</code>. Source Populated from <code>Variable.csv</code> (e.g. <code>internal_db</code>, <code>third_party</code>). TimeUnit From <code>Variable.csv</code> (e.g. <code>week</code>, <code>month</code>). data_structure From <code>Variable.csv</code> (e.g. <code>time-series</code>, <code>cross-sectional</code>). exp_perc_contribution Two numbers between \u20131 and 1 separated by <code>;</code> (\u2013100% to +100%). Pre-populated with <code>-1;1</code> to allow full range. refresh_priors - <code>Y</code> = recompute new priors at the midpoint of <code>exp_perc_contribution</code> - <code>N</code> = use priors already defined in <code>Variable.csv</code> or your custom-priors file <p>The Scoring_Criteria sheet controls how each simulation is evaluated. By setting weights through the importance column, you can guide the GA to prioritize one or multiple performance metrics, adapting the optimization to your analysis goals. </p> <p>This makes it easy to tailor the scoring logic to different project needs\u2014whether you want to maximize model fit, enforce business constraints, or balance multiple objectives simultaneously.</p> Field Type Description Example Notes metric string The name of the metric. <code>\"R2\"</code> Not editable metric_type string A human-readable category or description of the metric. <code>\"Model fit quality (adjusted R2)\"</code> Not editable panel string Identifier for the panel or segment this metric belongs to. <code>\"region_1\"</code> Not editable threshold_min float The lower bound of the \u201cacceptable\u201d range for the metric. <code>0.9</code> Nullable; min \u2264 max threshold_max float The upper bound of the \u201cacceptable\u201d range for the metric. <code>1</code> Nullable; \u2265 min importance_raw number Raw importance score (unitless). <code>5</code> \u2265 0 importance_pct float Importance as a percentage of the total (0\u20131). <code>0.1667</code> Calculation; not editable <p>The Selection_Rules sheet is optional and helps filter out simulations that don't meet specific criteria. </p> <p>For instance, if you're testing five price variables but want the final model to include only one of them, you can use this sheet to define minimum and maximum limits for how many variables from the same group can be included. This ensures the algorithm respects structural or business constraints during optimization.</p> <p>To use this function, the user must provide:</p> <ul> <li>Basic numeric settings for the genetic algorithm (e.g., population size, generations, seed).</li> <li>Logical flags to control simulation filtering and behavior.</li> <li>Optional numeric thresholds for contribution filtering and performance.</li> </ul> <p>The function returns a list containing several elements that summarize the results of the genetic algorithm optimization.</p> <p>The <code>sim_summary</code> is a data frame that provides an overview of all simulations along with their corresponding scores, allowing users to compare overall performance. </p> <p>The <code>sim_specs</code> element is a list detailing the specific parameter configurations used in each simulation. </p> <p>For a deeper evaluation, <code>sim_scores</code> contains a data frame with more granular scoring information for each run. </p> <p>The output also includes <code>sim_priors</code>, which lists any prior constraints applied during the optimization, and <code>original_constraints</code>, a data frame capturing the initial set of modeling constraints. </p> <p>Finally, the <code>seed</code> value used during the run is returned to ensure reproducibility.</p>"},{"location":"advanced-tools/#example-row","title":"Example Row","text":"Orig_Variable Variable_Group Include VaryBy Transform TransformType Lag Scale Effective Recency Decay Period Window Length Peak A B C Source TimeUnit data_structure exp_perc_contribution refresh_priors TV_Spend Media test None Y lag 1;4 1;8 0;5 0.1;0.5 1;3 1;4 1;4 2;6 1 10;50;100 -2;-0.5 Variable.csv week time-series -1;1 Y"},{"location":"advanced-tools/#tips-reminders","title":"Tips &amp; Reminders","text":"<ul> <li>Semicolon (<code>;</code>) is the universal separator for all ranges.</li> <li>Scale is blank by default\u2014only populate if your workflow explicitly requires it.</li> <li>Verify that every <code>TransformType</code> you use is implemented in your GA engine.</li> <li>Double-check your <code>Variable_Group</code> names against the <code>Selection_Rules</code> tab to avoid typos.</li> <li>Use this spec as your master document; apply your corporate styles (fonts, numbering, branding) as needed.</li> </ul>"},{"location":"advanced-tools/#unnesting-models","title":"Unnesting Models","text":"<p>Unnesting refers to breaking down complex models into simpler, more manageable parts. This is useful when analyzing submodels or when you want to examine the components of a hierarchical structure.</p>"},{"location":"advanced-tools/#purpose-and-when-to-use","title":"Purpose and When to Use","text":"<p>Unnesting is helpful when you need to isolate the effects of individual components in a nested model.</p>"},{"location":"function-help/","title":"Function Documentations","text":"<p>For help with functions, you can use R's built-in help system. For example:</p> <p>To get detailed documentation for a function, use:</p> <pre><code>??msmp.emea::function_name\n</code></pre> <p>This will open the help page for the specified function.</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>The first step is to install the <code>msmp.emea</code> package on your machine. Follow the steps below to install the package and verify that everything is set up correctly.</p> <p>The <code>msmp.emea</code> package is hosted on Bitbucket.</p> <p>If you or your team need access, please contact us at nicholas.smerald@annalect.com, bingen.gan@annalect.com, or giuseppe.nicoletti@annalect.com to request repository permissions.</p>"},{"location":"getting-started/#authentication-requirements","title":"Authentication requirements","text":"<p>To download the package from our private Bitbucket repository, you must authenticate your access. Please ensure the following:</p> <ul> <li>You have access to the Bitbucket repository.</li> <li>You have created a Bitbucket App Password with the appropriate permissions (typically read access to repositories). This is required because Bitbucket no longer supports account passwords for Git operations.</li> </ul> Bitbucket UsernameApp PasswordPro-tip <p>How to Find Your Bitbucket Username:</p> <ul> <li>Log in to your Bitbucket account</li> <li>Go to your Account settings page</li> <li>Under Bitbucket profile settings, look for the Username field \u2014 this is the username you'll use when authenticating with Git or installing packages.</li> </ul> <p>Creating a Bitbucket App Password:</p> <ul> <li>Log in to your Bitbucket account</li> <li>Go to your App passowrds page</li> <li>Click Create app password.</li> <li>Give it a label (e.g., \u201cmsmp.emea install\u201d).</li> <li>Select the minimum required permissions (usually under \"Repositories\" &gt; \"Read\").</li> <li>Save the password somewhere secure \u2014 you won't be able to see it again.</li> </ul> <p>To avoid re-entering your Bitbucket username and password each time, you can store them securely in your local <code>.Rprofile</code> so they\u2019re automatically loaded into your R environment.</p> <p>Step-by-step instructions:</p> <ul> <li>Open your <code>.Rprofile</code> by running the following command in your R console:</li> </ul> <pre><code>usethis::edit_r_profile()\n</code></pre> <ul> <li>Paste the following lines into the file, replacing the placeholders with your actual Bitbucket username and password:</li> </ul> <pre><code># Set Bitbucket credentials (replace with your actual username and password)\noptions(bitbucket_user = \"my_bitbucket_user\")\noptions(bitbucket_pass = \"my_bitbucket_password\")\n\n# Automatically load credentials into your environment\nbitbucket_user &lt;- getOption(\"bitbucket_user\")\nbitbucket_pass &lt;- getOption(\"bitbucket_pass\")\n</code></pre> <ul> <li>Save the file and restart your R session to apply the changes. Note: This method stores your credentials in plain text. </li> </ul>"},{"location":"getting-started/#dependencies","title":"Dependencies","text":"<p>Before installing the <code>msmp.emea</code> package, make sure the following dependencies are available on your machine:</p> <ul> <li><code>devtools</code>: This package is required to install packages directly from Git repositories (like Bitbucket).</li> </ul> <p>You can install it from CRAN using:</p> <pre><code>install.packages(\"devtools\")\n</code></pre>"},{"location":"getting-started/#troubleshooting","title":"Troubleshooting","text":"System dependenciesWindows usersmacOS users  <p>Note: <code>devtools</code> itself has several system-level dependencies (e.g., Rtools on Windows or Xcode on macOS). Make sure these are installed if you run into errors during installation.</p> <p>Before installing the package, it's important to set the download method to \"wininet\" to avoid potential issues with downloading files. This method is specifically designed for compatibility with Windows and can help prevent common errors related to internet connectivity or HTTPS certificate validation. Please run the following command in your R session before installing the package:</p> <pre><code>options(download.file.method = \"wininet\")\n</code></pre> <p>In most cases, no additional setup is needed before installing packages. However, if you encounter issues with package downloads\u2014especially related to HTTPS or certificates\u2014you can explicitly set the download method to \"libcurl\", which is well-supported on macOS.</p> <p>To do this, run the following command before installing the package:</p> <pre><code>options(download.file.method = \"libcurl\")\n</code></pre> <p>This can help ensure stable and secure downloads using the system's native networking libraries.</p>"},{"location":"getting-started/#installation-type","title":"Installation type","text":"<p>You may be installing the <code>msmp.emea</code> package for the first time, or updating an existing installation to ensure you\u2019re using the latest version. Follow the appropriate instructions below.</p> Fresh installUpdateBeta Testers <p>Use this option if you\u2019re installing the package for the first time:</p> <pre><code>remotes::install_bitbucket(\n  repo = \"omguk-annalect/msmp.emea\", \n  auth_user = bitbucket_user, \n  password = bitbucket_pass)\n</code></pre> <p>If you already have the package installed and want to update it:</p> <ul> <li>First, uninstall the existing version:</li> </ul> <pre><code>remove.packages(\"msmp.emea\")\n</code></pre> <ul> <li>Restart your R session to clear any locked namespace.</li> <li>Reinstall the latest version from Bitbucket:</li> </ul> <pre><code>remotes::install_bitbucket(\n  repo = \"omguk-annalect/msmp.emea\", \n  auth_user = bitbucket_user, \n  password = bitbucket_pass)\n</code></pre> <p>This section is intended for advanced users or testers who need to install a specific development version of the package.</p> <p>If you need to install a version from a branch other than master, or from a specific commit (e.g., to test changes), you can use the ref argument in the remotes::install_bitbucket() function:</p> <pre><code>remotes::install_bitbucket(\n  repo = \"omguk-annalect/msmp.emea\",\n  ref = \"branch-name-or-commit-hash\",\n  auth_user = bitbucket_user,\n  password  = bitbucket_pass\n)\n</code></pre> <p>Replace \"branch-name-or-commit-hash\" with the name of the development branch (e.g., \"dev-feature-x\") or a specific commit SHA (e.g., \"9f8c3a2d4e\").</p>"},{"location":"getting-started/#check-installation-and-version","title":"Check Installation and Version","text":"<p>After loading the package, run the following to confirm the version installed:</p> <pre><code>library(msmp.emea)\npackageVersion(\"msmp.emea\")\n</code></pre> <p>If the output shows the expected version number (e.g., v0.61.3), the installation was successful.</p>"},{"location":"hd-mmm/","title":"HD MMM Workflow","text":"<p>This document serves as a guide to help users run HD MMM projects using the <code>msmp.emea</code> package. This document and the codebase are maintained by the Annalect EMEA team, feel free to reach out to the team on any questions you have.</p> <p>The flowchart below outlines a high level overview of how a HD project will look like.</p> <p></p>"},{"location":"hd-mmm/#pre-requisites","title":"Pre-requisites","text":"<p>Before going into the project setup, there are a few pre-requisites that we would like to outline:</p> <ol> <li> <p>Have the latest package version of <code>msmp.emea</code> installed. Link to the repo can be found here: msmp.emea</p> </li> <li> <p>An MMM model. HD is a build on top of MMM so it requires an already established MMM model. Do note that the codebase requires the user to create the MMM models within the <code>msmp.emea</code> environment. If your MMM models are built using another solution, do reach out to a member of the team to discuss the best way forward.</p> </li> <li> <p>Media data splits. Having good data is central to a HD model's success. HD integrates this information by incorporating two additional files on top of the already established MMM model - HD template and HD meta files (See examples below). Both files can be created from the media data using the <code>msmp.emea::process_hd_data()</code> function within the package.</p> </li> </ol>  Example of a HD template table  Example of a HD meta table  Orig_Variable Next_Level_Down tv_grps tv_tactical_grps tv_grps tv_brand_grps tv_grps tv_tactical_puba_grps tv_tactical_grps tv_tactical_pubb_grps tv_tactical_grps tv_brand_pubb_grps tv_brand_grps tv_brand_pubc_grps tv_brand_grps Orig_Variable Group1 Group2 Group3 tv_tactical_puba_grps TV Tactical PubA tv_tactical_pubb_grps TV Tactical PubA tv_brand_pubb_grps TV Brand PubB tv_brand_pubc_grps TV Brand PubC"},{"location":"hd-mmm/#project-setup","title":"Project Setup","text":"<p>In this section, we will walk through the setup of a HD model using the RMarkdown template in detail. This guide will cover each step in the Rmd template and explain what it is trying to achieve.</p> <ol> <li> <p>Initial HD project setup</p> <ol> <li>Intialise the Rmd file<ul> <li>With the <code>msmp.emea</code> package installed, you should be able to see a HD MMM RMarkdown template. Initialise this file within your project folder. Save this file in the same location as your MMM model Rmd. You can create a template from RStudio by following the instruction below.</li> <li> <p>File -&gt; New File -&gt; R Markdown... -&gt; From Template -&gt; HD-mmm -&gt; Ok</p> </li> </ul> </li> <li>Define Yaml Parameters<ul> <li>Start by defining Yaml parameters at the top of the file. Ensure all parameters are accurate, particularly <code>mmm_model_id</code>, which must match the corresponding entry in the <code>table_of_model_ids.csv</code></li> <li> <p><pre><code>---\ntitle: \"Project Title\"\nauthor: \"Your name\"\ndate: \"Date\"\nparams:\n  model_client: \"client_name\"\n  model_product: \"product1\"\n  model_region: \"country\" \n  model_year: \"2023\"\n  model_version: \"1.0\"\n  model_kpi: \"my_kpi\"\n  model_panel: FALSE\n  mmm_model_id: \"Your MMM model ID\"\n  hd_model_version: \"v_1.0\"\n---\n</code></pre> 1.Set Date Ranges</p> </li> <li>Define the transform and modelling date ranges of your HD model. These date ranges will need to be the same as your MMM model as HD is very sensitive to this.</li> <li>For example, you can have a case where your transform start date is a month earlier than your actual model start date to take into account for media adstocks.</li> </ul> </li> </ol> </li> <li> <p>Setting Up and Loading in Data</p> <ol> <li> <p>Run Initialization</p> <ul> <li>Execute the <code>hd_mmm_init()</code> function to generate the folder structure required for the project.</li> <li>Based on the parameters in the Yaml file, it will create a folder called <code>07_hd_mmm</code> at <code>{model_client}_{model_year}/{model_region}_{model_product}_{model_kpi}/{model_version}</code></li> </ul> </li> <li> <p>Populate the required files for the project</p> <ul> <li>HD Variables: The <code>07_hd_mmm/01_hd_settings/01_input_hd_variables</code> folder will be auto-populated with the Variables.csv file from the MMM model output folder. The user need only check the csv file such that all HD media variables have the labels at \"AggregateVariable\" column set to \"Media\" and \"Simulate\" column set to \"Y\".</li> <li>HD Template: User will need to copy the hd template csv file into the folder <code>07_hd_mmm/01_hd_settings/02_input_hd_template</code>. </li> <li>HD Meta: User will need to copy the hd meta csv file into the folder <code>07_hd_mmm/01_hd_settings/03_input_meta</code>. </li> <li>HD Data (Optional): If HD level data is already supplied at the MMM stage, there is nothing to do here. Otherwise, user will need to populate the folder <code>07_hd_mmm/01_hd_settings/04_input_hd_data</code> with the relevant csv files.</li> </ul> </li> <li> <p>Re-run the initialisation function</p> <ul> <li>Once the previous step has been completed. Re-run the <code>hd_mmm_init()</code> function.</li> <li>If successful, you should be able to see 3 new files in the <code>07_hd_mmm/01_hd_settings</code> folder.<ul> <li><code>{mmm_model_id}_HDModObj.RData</code>: A copy of your model object</li> <li><code>{mmm_model_id}_HDVariables.csv</code>: HD variables csv file, it contains all the information on variables in the model and any HD level variables</li> <li><code>{mmm_model_id}_Meta.csv</code>: HD meta file</li> </ul> </li> </ul> </li> </ol> </li> <li> <p>Setup HD Variables, Meta and Weights file</p> <ol> <li> <p>At this stage, we should already have most of the HD files setup. The crucial step in this chunk is to make sure that the <code>PreWeights</code> for each HD variables are populated correctly. To facilitate this, user should use the <code>update_hd_preweights()</code> function to update the preweights accordingly. For any media variables that cannot be auto-populated by the function, the user can use the <code>vars</code> and <code>preweights</code> argument to populate them manually.</p> </li> <li> <p>The key thing to keep in mind is that all HD media variables should be in the same scale (i.e. all HD variables are impressions metric or all are in clicks metrics or roughly in the same ballpark in terms of representative size) due to the weight optimization algorithm which rescales these variables.</p> </li> <li> <p>If this chunk ran successfully, you should be able to see a new file in the <code>07_hd_mmm/01_hd_settings</code> folder.</p> <ul> <li><code>{mmm_model_id}_Weights.csv</code>: HD weights file, this file is where user will provide information on the HD weights (This file will open once the chunk runs successfully)</li> </ul> </li> <li> <p>Next step for the user will be to update the Weights file</p> <ul> <li>User will need to update the <code>Lower_Weight</code> and <code>Upper_Weight</code> columns which corresponds to your HD variables. A common initial bounds to use is [0.7,1.3]. (An example is shown below)</li> <li> <p>Here is a brief explanation of what each column of the file means:</p> <ul> <li>Group &amp; Value: These column corresponds to the group and group names of all variables from the meta file. <code>Group1</code> corresponds to your MMM level variables whereas the subsequent groups <code>Group2</code>, <code>Group3</code>, etc. corresponds to the HD level groupings.</li> <li>Weight: Weight assigned to the group, bigger number means bigger importance. All weights are initialised to be 1. Weight of 1s for all groups will give you the same results as your MMM model.</li> <li>Lower_Weight &amp; Upper_Weight: Lower and upper bound of the weights that you allow the algorithm to explore. You should only set Lower and Upper weights for HD groups, i.e. all <code>Group1</code>, <code>Intercept</code>, <code>Dependent</code>, and <code>Base</code> values should be fixed at 1.</li> <li>Uncontrolled_Weight: You can ignore this column as this will be populated when we run the weights optimization algorithm.</li> <li>Example of a weights table:</li> </ul> Group Value Weight Lower_Weight Upper_Weight Uncontrolled_Weight Group1 Intercept1 1 1 1 1 Group1 Base1 1 1 1 1 Group1 Dependent1 1 1 1 1 Group1 Display 1 1 1 1 Group1 YouTube 1 1 1 1 Group2 Direct 1 0.7 1.3 1 Group2 Programmatic 1 0.7 1.3 1 Group3 Home 1 0.7 1.3 1 Group3 Technology 1 0.7 1.3 1 Group3 Fashion 1 0.7 1.3 1 </li> </ul> </li> </ol> </li> <li> <p>Update the weights file and run a series of pre-transformation checks</p> <ol> <li>In this chunk, the functions will run a series of checks on the HD spec and control files (meta and weights file) to detect any errors or flag any warnings.</li> </ol> </li> <li> <p>Run Checks and Create Variable Transformations + Weightings for HD MMM</p> <ol> <li>At this stage we are almost done with the HD setups and will be able to run the optimization algorithm soon. One last step that we need to do is to check whether we are able to recreate the MMM model outputs from our HD setup. This is an important step as it gives us confidence that we have set HD up for success.</li> <li>Let's go through some of the key functions in this chunk:<ul> <li><code>HD_Variable_Tranformations()</code>: HD version of Transform()</li> <li><code>Distribute_Weights()</code>: Apply weights from the weights file to the HD variables. At this stage all weights should be 1 (Unless the user has provided a different set of weights to initalise HD)</li> <li><code>Measures_of_Extreme_Transformations()</code>: Gives information on how shape of the adstocks and diminishing returns transformations. An example is shown below               Example for adstock extremity.                       Example for DR extremity.          </li> <li><code>hd_update_priors()</code>: Updates the priors of the model as the HD variables are in a different scale from the MMM model</li> <li><code>Decomposition_Levels()</code>: HD version of Decomp()</li> </ul> </li> <li>This chunk should run fine without needing any edits to the code. Once the chunk runs, it should create two comparison tables - a decomposition table comparison and a coefficients table comparison.<ul> <li>Decompoistion table comparison: This is what is important. We should see minimal differences between the two decomps.</li> <li>Coefficient table comparison: We can see that the HD model's coefficients for media variables look different from their MMM counterpart. This is because of the scaling that is applied to those variables which will be important in the optimization algorithm.</li> </ul> </li> </ol> </li> <li> <p>Weights Optimization     There are two stages when it comes to optimization of HD weights. First, the algorithm will search for the best possible weights within the bounds specified. After that, a fine tuning algorithm will be run to penalize weights that are not contributing significantly. The idea behind penalizing weights is similar to that of a Lasso or Ridge regression. Similar to how a penalized coefficient will be pulled towards 0, in this case, a penalized weight will be pulled back towards 1. We have broken down this stage into 3 sections: (1) Establishing a rough range the optimal penalty might sit in, (2) Do a grid search of the penalty range, (3) Run the optimization algorithm with the optimal penalty value</p> <ol> <li> <p>Uncontrolled weights and penalty range</p> <ul> <li>In this chunk, we are looking to understand the range of penalty values that we should test for the model. When we run the optimization algorithm with <code>UCOpt</code> set to TRUE, we can see a suggested penalty range printed in the console.</li> </ul> <pre><code>Set the penalty for optimization somewhere between 65.2 and 2693.4 for this data.\n  With a penalty of 271.9 preventing only the worst over-fitting but has very high R-Squared.\n  A penalty of 753.8 a good average amount of control.\n  And a penalty of 936.5 allows only the most statistically significant weights. \n</code></pre> <ul> <li>Besides that, the uncontrolled weights will also give us an idea of whether the bounds we set for our groups are sufficient. For example, if the uncontrolled weight of a group goes beyond its upper or lower bound, it is advised to widen the bound.</li> </ul> </li> <li> <p>Testing penalty values</p> <ul> <li>Once we have the initial penalty values that we can be testing, we can input them into the <code>penalty_vals</code> vector and run the chunk to test out these values. The chunk willl take a while to run, and once finished, it will create a folder called <code>hd_penalty_loop_outputs</code> in the main folder and output the results in an excel file. We will talk more about analysing this output in the next section.</li> <li>This is an iterative process, which means we will need to run this chunk multiple times until we find a good penalty value that works well with the model. For example, I have tested penalty values [10, 20, 50, 75, 100] and have found that 20 seems to be giving me the most optimal result. Next, I will test the penalty values [15, 18, 21, 25, 30] to determine which values in the vicinity of 20 gives me a better result. As you can see, it can take quite a few tries to get to our final penalty value.</li> <li>Do note that optimal penalty value may vary from one group to another, so it is important to balance this as we can only have one penalty value in the end.</li> </ul> </li> <li> <p>Run optimization with optimal penalty value</p> <ul> <li>After testing all the penalty values and have found the one that is suitable for our model, input that value into the weights optimization function to create our final output.</li> <li>With this, we should have everything we need - Final HD Weights, HD Decomp table, and HD Response Curves. All that we need to do now is save the output.</li> </ul> </li> </ol> </li> </ol>"},{"location":"hd-mmm/#analyzing-hd-outputs","title":"Analyzing HD Outputs","text":"<p>This section aims to breakdown the excel file output generated from the penalties testing stage. In the file, you will see 4 sheets:</p> <ol> <li> <p>RanWeights</p> <ul> <li>As you can see, this sheet resembles the weights file quite a bit, with a few additional columns. It displays the random weights that we get from the optimization algorithm. If you recall, the optimization algorithm runs in two stages, it first gets the best weight in the range, then it refines the weights using the penalty value. Random weights are the weights we get from the first stage of the optimization (best weights in the range). Therefore, these weights are optimized without the use of penalty values. You can think of these weights as weights we get from a penalty of 0.</li> <li>Purpose: To understand whether the algorithm is giving us consistent results across each run. This is very important as it tells us that the algorithm has converged. However, when we see inconsistencies between runs, the user have to dive into why this is the case. There are a few explanation as to why the weights may not have converged:<ul> <li>Size of the group is too small (inidicated by the size column). When the size is too small, the choice of giving it a weight close to the upper bound or the lower bound yields insignificant change to the model. In this case, user can choose not to weight them at all (set lower and upper bounds to 1).</li> <li>Run time is too short. When the search range is large or there are many groups in a level, the search space is big and the algorithm hasn't had the chance to explore a good chunk of the parameter space. In this case, it will be wise to increase the run time.</li> <li>In cases where the groups are very big and relationship between groups are complex. It is sufficient to observe whether the weights are telling a consistent story, e.g. Group X in Level 2 consistently outperforms the other groups in the same level although it takes on different values in each run.</li> </ul> </li> </ul> </li> <li> <p>Weights</p> <ul> <li>This sheet is very similar to the RanWeights sheet, with a slight difference whereby instead of random weights, these weights are the fine tuned version of random weights (weights we get from the second stage of the optimization algorithm). Therefore, these weights are heavily influenced by the penalty values.</li> <li>Purpose: Look for consistencies across different runs within the same penalty value. Choosing the best penalty value will be up to the analyst's judgement. However, do keep in mind that the weights should be reasonable and tell us a meaningful story. (e.g., A set of weights of 1s as our output isn't telling us anything new as these are the default results we get from our MMM model)</li> </ul> </li> <li> <p>Effect</p> <ul> <li>You can think of effect as a value showing how significant the group is at increasing the model's performance when it's weight is increased/ decreased by a small step in either direction. The bigger the value, the more significant the group is.</li> </ul> </li> <li> <p>Decomp</p> <ul> <li>As looking at the decomposition table is an important factor while deciding on penalty values, its corresponding decomp table of each weights optimization run is saved here so the user can always refer to it when needed.</li> </ul> </li> </ol>"},{"location":"main_documentation/","title":"Main documentation","text":""},{"location":"main_documentation/#mmm-section","title":"MMM Section","text":""},{"location":"main_documentation/#introduction","title":"Introduction","text":"<p>Marketing Mix Modeling (MMM) is a powerful analytical approach that helps businesses understand the impact of marketing activities on business outcomes. By analyzing data across multiple marketing channels, MMM helps you optimize marketing spend, predict future outcomes, and make data-driven decisions. </p> <p>The <code>msmp.emea</code> R package provides a structured approach to perform MMM analysis with ease. It automates many of the key tasks required in an MMM analysis, such as data preparation, model estimation, and result interpretation.</p> <p>With <code>msmp.emea</code>, analysts can:</p> <ul> <li>Set Up Projects Easily: Automatically generate a structured project folder to keep analyses organized.</li> <li>Ingest and Clean Data: Read client data from various sources and apply essential preprocessing steps to make sure it's ready for analysis.</li> <li>Transform Data: Apply necessary transformations such as scaling, lagging, and feature engineering to prepare the data.</li> <li>Estimate Model Coefficients: Fit the MMM model to the data and extract key parameters for analysis.</li> <li>Decompose Results: Break down the contribution of each marketing channel for actionable insights.</li> <li>Calculate Response Curves: Understand diminishing returns and optimize media spend.</li> <li>Export and Save Results: Store results in structured formats for further analysis and reporting.</li> </ul> <p>This guide will walk you through the entire process of using the <code>msmp.emea</code> package to conduct MMM analysis. Whether you\u2019re new to MMM or an experienced analyst, <code>msmp.emea</code> streamlines the process and helps you focus on interpreting results and driving strategic decisions.</p>"},{"location":"main_documentation/#package-installation","title":"Package Installation","text":"<p>The first step is to install the <code>msmp.emea</code> package on your machine. Follow the steps below to install the package and verify that everything is set up correctly.</p> <p>The <code>msmp.emea</code> package is hosted on Bitbucket.</p> <p>If you or your team need access, please contact us at nicholas.smerald@annalect.com, bingen.gan@annalect.com, or giuseppe.nicoletti@annalect.com to request repository permissions.</p>"},{"location":"main_documentation/#authentication-requirements","title":"Authentication requirements","text":"<p>To download the package from our private Bitbucket repository, you must authenticate your access. Please ensure the following:</p> <ul> <li>You have access to the Bitbucket repository.</li> <li>You have created a Bitbucket App Password with the appropriate permissions (typically read access to repositories). This is required because Bitbucket no longer supports account passwords for Git operations.</li> </ul> Bitbucket UsernameApp PasswordPro-tip <p>How to Find Your Bitbucket Username:</p> <ul> <li>Log in to your Bitbucket account</li> <li>Go to your Account settings page</li> <li>Under Bitbucket profile settings, look for the Username field \u2014 this is the username you'll use when authenticating with Git or installing packages.</li> </ul> <p>Creating a Bitbucket App Password:</p> <ul> <li>Log in to your Bitbucket account</li> <li>Go to your App passowrds page</li> <li>Click Create app password.</li> <li>Give it a label (e.g., \u201cmsmp.emea install\u201d).</li> <li>Select the minimum required permissions (usually under \"Repositories\" &gt; \"Read\").</li> <li>Save the password somewhere secure \u2014 you won't be able to see it again.</li> </ul> <p>To avoid re-entering your Bitbucket username and password each time, you can store them securely in your local <code>.Rprofile</code> so they\u2019re automatically loaded into your R environment.</p> <p>Step-by-step instructions:</p> <ul> <li>Open your <code>.Rprofile</code> by running the following command in your R console:</li> </ul> <pre><code>usethis::edit_r_profile()\n</code></pre> <ul> <li>Paste the following lines into the file, replacing the placeholders with your actual Bitbucket username and password:</li> </ul> <pre><code># Set Bitbucket credentials (replace with your actual username and password)\noptions(bitbucket_user = \"my_bitbucket_user\")\noptions(bitbucket_pass = \"my_bitbucket_password\")\n\n# Automatically load credentials into your environment\nbitbucket_user &lt;- getOption(\"bitbucket_user\")\nbitbucket_pass &lt;- getOption(\"bitbucket_pass\")\n</code></pre> <ul> <li>Save the file and restart your R session to apply the changes. Note: This method stores your credentials in plain text. </li> </ul>"},{"location":"main_documentation/#dependencies","title":"Dependencies","text":"<p>Before installing the <code>msmp.emea</code> package, make sure the following dependencies are available on your machine:</p> <ul> <li><code>devtools</code>: This package is required to install packages directly from Git repositories (like Bitbucket).</li> </ul> <p>You can install it from CRAN using:</p> <pre><code>install.packages(\"devtools\")\n</code></pre>"},{"location":"main_documentation/#troubleshooting","title":"Troubleshooting","text":"System dependenciesWindows usersmacOS users  <p>Note: <code>devtools</code> itself has several system-level dependencies (e.g., Rtools on Windows or Xcode on macOS). Make sure these are installed if you run into errors during installation.</p> <p>Before installing the package, it's important to set the download method to \"wininet\" to avoid potential issues with downloading files. This method is specifically designed for compatibility with Windows and can help prevent common errors related to internet connectivity or HTTPS certificate validation. Please run the following command in your R session before installing the package:</p> <pre><code>options(download.file.method = \"wininet\")\n</code></pre> <p>In most cases, no additional setup is needed before installing packages. However, if you encounter issues with package downloads\u2014especially related to HTTPS or certificates\u2014you can explicitly set the download method to \"libcurl\", which is well-supported on macOS.</p> <p>To do this, run the following command before installing the package:</p> <pre><code>options(download.file.method = \"libcurl\")\n</code></pre> <p>This can help ensure stable and secure downloads using the system's native networking libraries.</p>"},{"location":"main_documentation/#installation-type","title":"Installation type","text":"<p>You may be installing the <code>msmp.emea</code> package for the first time, or updating an existing installation to ensure you\u2019re using the latest version. Follow the appropriate instructions below.</p> Fresh installUpdateBeta Testers <p>Use this option if you\u2019re installing the package for the first time:</p> <pre><code>remotes::install_bitbucket(\n  repo = \"omguk-annalect/msmp.emea\", \n  auth_user = bitbucket_user, \n  password = bitbucket_pass)\n</code></pre> <p>If you already have the package installed and want to update it:</p> <ul> <li>First, uninstall the existing version:</li> </ul> <pre><code>remove.packages(\"msmp.emea\")\n</code></pre> <ul> <li>Restart your R session to clear any locked namespace.</li> <li>Reinstall the latest version from Bitbucket:</li> </ul> <pre><code>remotes::install_bitbucket(\n  repo = \"omguk-annalect/msmp.emea\", \n  auth_user = bitbucket_user, \n  password = bitbucket_pass)\n</code></pre> <p>This section is intended for advanced users or testers who need to install a specific development version of the package.</p> <p>If you need to install a version from a branch other than master, or from a specific commit (e.g., to test changes), you can use the ref argument in the remotes::install_bitbucket() function:</p> <pre><code>remotes::install_bitbucket(\n  repo = \"omguk-annalect/msmp.emea\",\n  ref = \"branch-name-or-commit-hash\",\n  auth_user = bitbucket_user,\n  password  = bitbucket_pass\n)\n</code></pre> <p>Replace \"branch-name-or-commit-hash\" with the name of the development branch (e.g., \"dev-feature-x\") or a specific commit SHA (e.g., \"9f8c3a2d4e\").</p>"},{"location":"main_documentation/#check-installation-and-version","title":"Check Installation and Version","text":"<p>After loading the package, run the following to confirm the version installed:</p> <pre><code>library(msmp.emea)\npackageVersion(\"msmp.emea\")\n</code></pre> <p>If the output shows the expected version number (e.g., v0.61.3), the installation was successful.</p>"},{"location":"main_documentation/#data-structure","title":"Data Structure","text":"<p>Before diving into model workflow, it's important to clarify how data should be structured, as this affects how the package processes inputs and ensures consistent behavior across different types of datasets \u2014 whether panel or non-panel.</p>"},{"location":"main_documentation/#panel-vs-non-panel-data","title":"Panel vs. Non-Panel Data","text":"<p>In the context of Marketing Mix Modeling (MMM), panel data refers to datasets that contain observations across multiple units (such as regions, brands, or stores) over time. Each unit has its own time series, allowing analysts to capture both temporal dynamics and cross-sectional variation.  This can improve model robustness by leveraging patterns across similar entities and supporting more generalizable insights.</p> <p>By contrast, non-panel data (also known as time series or aggregate data) includes a single stream of observations over time, typically representing national-level performance or a single entity. </p> <p>While simpler to manage, non-panel data limits the ability to control for unit-specific effects and can lead to more fragile estimates if the dataset is small or noisy.</p> Date Car Model Orders TV Spend Radio Spend 2022-01-01 Alpha 91 872.13 2916.01 2022-01-01 Beta 154 2412.97 3266.66 2022-01-01 Delta 115 3973.21 1752.63 2022-01-01 Gamma 96 175.27 4847.49 2022-01-08 Alpha 71 7417.53 3864.92 2022-01-08 Beta 151 1462.11 1039.69 2022-01-08 Delta 165 3163.78 3402.06 2022-01-08 Gamma 78 9267.57 2904.78 2022-01-15 Alpha 107 9244.82 2923.08 2022-01-15 Beta 91 2707.85 4926.91 <p> Note: Car Model is the panel identifier used to group data by vehicle type. </p>"},{"location":"main_documentation/#why-use-a-panel-format","title":"Why Use a Panel Format","text":"<p>Our modeling approach standardizes how data is treated by assuming a panel structure for all input datasets. This provides consistency in how models are built, regardless of the original data format. </p> <p>If a dataset is not naturally a panel (i.e., it contains only a single time series), we automatically add a grouping column to create a \"panel of one\". This ensures that all processing and modeling routines \u2014 such as decomposition, contribution analysis, and cross-validation \u2014 can be applied uniformly, without needing special handling for different data types.</p> Date Panel Col Orders TV Spend Radio Spend 2022-01-01 client_name 151 3550.62 4911.53 2022-01-08 client_name 129 5245.67 2383.74 2022-01-15 client_name 103 9522.32 1516.49 2022-01-22 client_name 151 7284.52 4516.02 2022-01-29 client_name 150 6993.12 4187.69 2022-02-05 client_name 111 5301.55 1624.52 2022-02-12 client_name 125 8073.22 4493.61 2022-02-19 client_name 155 2835.41 1832.87 2022-02-26 client_name 109 8590.96 4512.57 2022-03-04 client_name 143 826.44 2390.48 <p> Note: Panel Col identifies groups when panel structure is required. If the data isn't in panel format, this will be generated automatically. </p>"},{"location":"main_documentation/#advantages-of-a-unified-approach","title":"Advantages of a Unified Approach","text":"<p>Treating all datasets as panels simplifies the architecture and improves model scalability. It allows us to apply the same logic for feature engineering, constraints, and optimization routines \u2014 whether the user provides a multi-brand dataset or a single-country time series. </p> <p>This also makes it easier to expand to true panel use cases in the future, as the underlying structure already supports multiple groups. </p>"},{"location":"main_documentation/#folders-setup","title":"Folders Setup","text":"<p>This is the initial phase where (in your workflow template) you define the modeling scope, select the business KPIs (e.g., revenue, conversions), and determine the modeling granularity (e.g., weekly, country-level). The workflow will guide you to create a project folder structure and set configuration files or paths for your inputs and outputs.</p> <p>Once you run the <code>project_init()</code> function, a new folder structure will be created on your machine. This structure is designed to help organize your data and outputs so that the package can easily access the files it needs to run the analysis.</p>"},{"location":"main_documentation/#folders-and-file-overview","title":"Folders and File Overview","text":"<p>The following files and folders are automatically created by the package during project initialization. They provide a standardized structure to support a smooth and reproducible modeling workflow.</p> <p></p> 01_data02_eda03_model_workflow04_model_settings 05_model_output06_documentationmodel_id.txt <p>This folder contains all raw and pre-processed input data used in the modeling process. This may include media spend, sales or conversions, control variables (e.g., pricing, promo), seasonal flags, and any other relevant time-series data. Ideally, files here are versioned and read-only, ensuring consistency across runs.</p> <p>The Exploratory Data Analysis (EDA) folder holds visualizations, summary statistics, and diagnostics used to understand and validate the input data before modeling.</p> <p>Note: this feature is still under development</p> <p>This folder contains a copy of the main R markdowns that run the modeling pipeline. These scripts handle tasks such as initializing the model object, setting up the model, transforming variables, running the estimation, and generating outputs. Think of this as the \"engine room\" of your workflow.</p> <p>This folder stores configuration files (mostly .CSV) that define model inputs and hyperparameters. These settings include which variables are included, prior distributions, transformation settings (e.g., adstock, saturation), and modeling time windows. </p> <p>This folder captures all outputs generated by the model, such as contribution decompositions, model diagnostics, or a copy of the model object. It may also include visual reports or summary tables. Outputs here are often used to support stakeholder decision-making.</p> <p>This folder is created for the users to store documentation about the project: modeling rationale, decisions, assumptions, meeting notes, and final deliverables. It might also contain markdown files, slide decks, or PDFs that explain the project flow, outcomes, and business recommendations.</p> <p>This file contains a unique identifier for the model run. It helps track and reference a specific set of modeling configurations, inputs, and outputs, especially in workflows that involve multiple iterations or parallel experiments.</p> <p>The <code>model_id.txt</code> file typically includes a short string that is automatically generated by the pipeline.</p> <p>Why it's important:</p> <ul> <li>Ensures traceability between model inputs and outputs.</li> <li>Allows consistent naming of output files.</li> <li>Makes collaboration easier by giving analysts a common reference point.</li> </ul> <p>Typical usage in the pipeline:</p> <ul> <li>Read in during model initialization to tag outputs.</li> <li>Stored alongside outputs and logs.</li> </ul>"},{"location":"main_documentation/#input-files","title":"Input Files","text":"<p>These are the key files you'll interact with throughout the modeling phase. They form the foundation of the workflow, guiding what data will be transformed, analyzed, and ultimately modeled.</p> Model Setup FileVariables File <p>The Model Setup file is the first configuration you'll edit when starting your analysis. It defines key parameters that control how the model is structured and what data is used. These settings guide both model estimation and response curve analysis.</p> <p>This file is essential for configuring your analysis and should be carefully reviewed and updated before running any model.</p> Parameter Explanation Mandatory_Field ModelForm Specifies the regression model form. Options include 'lin_lin' (linear), 'log_lin' (log-transformed response), and 'mc_lin' (mean-centered transformed response). Yes Panel Indicates whether the model supports panel data structure. Set to 'Y' to ensure compatibility, even for non-panel use cases. Yes Time Name of the time-related column in the dataset, typically representing months or weeks. Yes Geo Not currently in use. No CS Defines the main cross-sectional unit used in panel models (e.g., product, market, or vehicle). Yes CS2 Optional second-level cross-sectional identifier (not currently available) No BeginDate Start date for the analysis period. Format should be DD/MM/YYYY. Yes EndDate End date for the analysis period. Format should be DD/MM/YYYY. Yes numSubModel Optional. Specifies how many sub-models are linked to the main model. No Submodel_Link1 Name of the parent variable in the main model used to link to the first sub-model. No Submodel_Link2 Name of the parent variable used to link to the second sub-model. No Submodel_Link3 Name of the parent variable used to link to the third sub-model. No subModel1 Name or label of the first child sub-model to be used in hierarchical modeling. No subModel2 Name or label of the second child sub-model to be used in hierarchical modeling. No subModel3 Name or label of the third child sub-model to be used in hierarchical modeling. No SimStart Start date for the simulation period used in response curve generation. Format: DD/MM/YYYY. Yes SimEnd End date for the simulation period used in response curve generation. Format: DD/MM/YYYY. Yes Mroi Increment size used to simulate changes in media investment when generating response curves. Yes <p>The Variables file defines all variables used in the model along with their inclusion status and transformation settings. This file gives you full control over how each variable is treated in the modeling pipeline.</p> <p>This file is critical for customizing model inputs and ensuring each variable is preprocessed appropriately for the analysis.</p> Column_Name Explanation Workflow_Component Orig_Variable Original name of the variable as it appears in the raw dataset All functions Trans_Variable Name to use for the variable after any transformation All functions AggregateVariable Indicates a grouping variable for aggregating similar sub-variables Decomposition Variable_Type Specifies the type of variable (e.g., Dependent, Trend, Default) Decomposition Include Binary flag (1/0) indicating if the variable should be included in the model All functions VaryBy Specifies if the variable coefficient varies by a grouping (only for panel data) Coefficients estimation Transform Whether the variable should be transformed (Y/N) - Keep this as default. Transformation TransformType Type of transformation (e.g., adstock, log, lag, saturation) Transformation Lag Number of periods to lag the variable Transformation Scale Scaling factor to adjust the variable values Transformation Effective Ad Response transformation (tbd) Transformation Recency Ad Response transformation (tbd) Transformation Decay Decay rate for adstock or adr (value between 0 and 1; a higher value means faster decay). Transformation Period Ad Response transformation (tbd) Transformation Window Size of the moving window (e.g., for rolling averages) Transformation Trim Currently not in use Transformation Length Maximum number of time periods over which advertising memory can persist. Transformation Peak Indicates the peak point in a adstock transformation. Transformation AT_Divisor Arc-Tangent parameter (rarely used) Transform (for diminising returns) NE_Divisor Negative Exponential parameter (rarely used) Transform (for diminising returns) A Ceiling of ABC curve (keep as 1) Transform (for diminising returns) B Parameter of ABC curve (typically set between 20\u201380% of the variable\u2019s maximum value.) Transform (for diminising returns) C Parameter of ABC curve (If c &gt; -1, the function is logarithmic; if c &lt; -1, the function follows an S-shaped curve). Transform (for diminising returns) Max_Grps Not in use Transformation Prior_Mean Prior mean for Bayesian estimation Coefficients estimation Prior_SD Prior standard deviation for Bayesian estimation Coefficients estimation PriorSD_Adj Adjustment factor for prior standard deviation Coefficients estimation Sign Not in use nan Override Not in use nan Simulate Indicates if the variable is used for response curves Response Curve RC_Shape Defines the shape of the response curve for the variable Response Curve Explore_correlation Whether to include the variable in correlation diagnostics EDA Explore_transformation Whether to explore alternate transformations during modeling EDA Spent_Variable Reference to the spend version of the variable (if separated from exposure) Response Curve Cost_per_unit Unit cost of the media (used in efficiency calculations) Response Curve Source Metadata field indicating where the variable came from Transformation TimeUnit Time granularity of the variable (e.g., weekly, monthly) Transformation"},{"location":"main_documentation/#modeling-workflow","title":"Modeling Workflow","text":"<p>Our workflows are designed to ensure consistency, transparency, and reproducibility across projects.</p> <p>The <code>msmp.emea</code> package supports two distinct yet complementary approaches for analyzing media effectiveness: a Bayesian Marketing Mix Modeling (Bayesian MMM) approach and a more granular High-Definition (HD) modeling approach. Both share a common foundation but are designed to answer different types of business questions.</p>"},{"location":"main_documentation/#overview-of-modeling-approaches","title":"Overview of Modeling Approaches","text":"Bayesian MMMHigh-Definition (HD) Modeling <p>The Bayesian MMM approach is a modern version of the classical Marketing Mix Modeling framework, implemented using Bayesian inference. This method enables the quantification of media effectiveness and ROI while explicitly accounting for uncertainty in parameter estimates.</p> <p>Key characteristics of the Bayesian MMM approach:</p> <ul> <li>Prior knowledge incorporation: Prior distributions can be used to incorporate historical learnings or domain expertise into the model.</li> <li>Flexibility: The Bayesian framework supports complex modeling features such as hierarchical structures, seasonality components, and non-linear saturation effects.</li> </ul> <p>This approach is ideal when the goal is to build robust, interpretable models with quantified uncertainty and leverage prior knowledge to stabilize estimates in data-scarce environments.</p> <p>HD MMM is a build on top of the current MMM toolkit where you would be able to take a more detailed look into the contributions of your total media channel. For example, two main strategies were used for a digital channel - strategy A and strategy B. </p> <p>The HD algorithm will then be able to approximate the effectiveness of each strategy based on the flighting pattern and give you a breakdown of each strategy's contribution that makes up the total digital channel's contribution in the MMM model.</p>"},{"location":"main_documentation/#workflow","title":"Workflow","text":"Bayesian MMMHigh-Definition (HD) Modeling"},{"location":"main_documentation/#workflow-templates","title":"Workflow Templates","text":"<p>The <code>msmp.emea</code> package includes a set of predefined workflow templates designed to guide you through the media modeling process. These templates are accessible directly from RStudio, helping ensure a standardized, efficient, and reproducible workflow.</p>"},{"location":"main_documentation/#available-templates","title":"Available Templates","text":"<ul> <li>Model-Workflow: A standard template for running a complete MMM analysis.</li> <li>HD-MMM: A template for Hierarchical Decomposition modeling, enabling granular analysis within channels.</li> <li>Unnest-Models: A utility template for unnesting models and analyzing their individual components.</li> </ul> <p>These templates streamline your workflow by reducing setup time, minimizing the risk of error, and ensuring all critical steps are included.</p>"},{"location":"main_documentation/#how-to-use-templates-in-rstudio","title":"How to Use Templates in RStudio","text":"<p>To launch a template in RStudio:</p> <ul> <li>Click on the New File icon.</li> <li>Select R Markdown.</li> <li>Choose From Template, then pick the relevant <code>msmp.emea</code> template.</li> </ul> <p>RStudio will create a new document pre-filled with the appropriate structure, guidance, and placeholders to help you get started quickly.</p>"},{"location":"main_documentation/#detailed-procedure","title":"Detailed Procedure","text":""},{"location":"main_documentation/#load-and-clean-data","title":"Load and clean data","text":"<p>In this step, raw data sources (media, sales, promotions, seasonality, etc.) are loaded and pre-processed. You\u2019ll standardize column formats, handle missing values, align time series, and possibly merge disparate datasets to create a unified modeling dataset.</p>"},{"location":"main_documentation/#model-object","title":"Model object","text":"<p>You create the base model object using the <code>msmp.emea</code> functions. This object acts as the container for all subsequent modeling steps and configurations. It typically includes raw input data, metadata, and placeholder slots for transformed data, priors, and model outputs.</p>"},{"location":"main_documentation/#model-setup","title":"Model setup","text":"<p>Here, you define modeling parameters such as the dependent variable (target), media channels, control variables, time windows, and holiday effects. This is where the modeling framework is initialized \u2014 effectively \u201ctelling\u201d the model what to expect.</p>"},{"location":"main_documentation/#model-specification","title":"Model specification","text":"<p>Also referred to as \"model spec,\" this step involves defining how variables enter the model: what transformations are applied (e.g., adstock, saturation), which priors are used in Bayesian estimation, and whether interactions or groupings are introduced. It\u2019s a critical step that shapes the econometric assumptions.</p>"},{"location":"main_documentation/#data-transformation-and-validation","title":"Data Transformation and Validation","text":"<p>At this stage, data is transformed according to the model spec: media variables may be adstocked, logged, or saturated. You also perform validation checks to ensure data aligns with model assumptions (e.g., no missing data, consistent timeframes).</p>"},{"location":"main_documentation/#run-model","title":"Run Model","text":"<p>You fit the model using the inference engine provided in <code>msmp.emea</code>. This step will also provide diagnostics for results inspection. You may iterate multiple times, adjusting specifications or priors based on initial results.</p>"},{"location":"main_documentation/#decomposition","title":"Decomposition","text":"<p>Here you decompose the predicted values into contributions from each variable or group of variables (e.g., media, price, promotions). This allows you to understand what\u2019s driving performance and quantify the ROI of each input.</p>"},{"location":"main_documentation/#response-curves","title":"Response Curves","text":"<p>Response curves (a.k.a. saturation curves) show how the output responds to incremental changes in each media variable. These are essential for budget planning and optimization, helping identify diminishing returns and efficient spend thresholds.</p>"},{"location":"main_documentation/#supported-transformations","title":"Supported Transformations","text":"<p>The <code>msmp.emea</code> package supports several transformations to handle data in ways that optimize the MMM process. Some of the key transformation types are:</p> TransformType Caller Explanation adstockv3 Adstock Applies a standard adstock transformation to model lagged and decaying media effects. adstockv4imp Adstock with rescaled impressions Similar to standard adstock but used for impression data, applying rescaling to account for volume. adr Ad response Applies an advertising response function, typically used for modeling non-linear saturation effects. lag Lag Shifts the variable backward in time to capture delayed effects. log Log Applies a logarithmic transformation to reduce skew and stabilize variance. ma Moving average Smooths the variable by averaging over a specified time window to reduce noise. abcnew For diminishing returns Applies a functional form tailored for diminishing returns (e.g., sigmoid or Hill-type curves). none No transformation Leaves the variable untransformed. Use when no preprocessing is required. customt() Custom transformation Applies a user-defined transformation using a formula-like string. For example, customt(\"x^2\") squares the input.\" boxcox Boxcox Applies a Box-Cox transformation to stabilize variance and approximate normality. <p>The <code>Transform</code> function allows you to apply multiple transformations by chaining them together using underscores (_). Each TransformType will be applied in the order specified, from left to right.</p>"},{"location":"main_documentation/#advanced-tools","title":"Advanced Tools","text":"<p>The features described in this section go beyond the core <code>msmp.emea</code> workflow. </p> <p>While they are not required for the standard analysis pipeline, they are designed to support analysts who need greater flexibility or advanced functionality when processing and modeling data. </p> <p>These tools aim to streamline common tasks, handle edge cases, and provide more control over specific steps in the modeling process, ultimately making the overall workflow more adaptable to different analytical needs.</p>"},{"location":"main_documentation/#new_ga","title":"new_ga","text":"<p>The <code>msmp.emea</code> package includes a function called <code>new_ga</code> that runs a genetic algorithm (GA) to find the best parameter values for a model simulation. It works by testing many different combinations of parameters and selecting those that lead to better simulation results, based on a score defined by the user. </p> <p>The goal is to maximize this score, so the function keeps improving the parameter sets over several generations. It automatically filters out poor or invalid solutions, applies any constraints set by the user, and ensures that only simulations meeting minimum performance standards are considered. </p> <p>This makes the function a useful tool for tuning models when the best settings are not known in advance.</p> <p></p>"},{"location":"main_documentation/#function-description","title":"Function description","text":"InitialisationInputsOutputs <p>The first time you run <code>new_ga</code>, it automatically creates a new Excel file in your project folder at \"07_ga_search_constraints/_ga_all_inputs.xlsx\". This file includes three sheets that define the full set of constraints the genetic algorithm will use to search for the optimal solution to your modeling problem.</p> Test_VariablesScoring_CriteriaSelection_Rules <p>The Test_Variables sheet controls how each raw variable from Variable.csv is used by the Genetic Algorithm (GA). Each row represents a single original variable and specifies:</p> Column Populate From / Allowed Values Orig_Variable The exact variable name as it appears in <code>Variable.csv</code>. Variable_Group Use the grouping column from <code>Variable.csv</code> to assign this variable to one of your pre-defined selection-rule groups. Include Controls GA inclusion: - <code>1</code> = force include - <code>0</code> = force exclude - <code>test</code> = let GA decide include vs. exclude VaryBy Coefficient variation across panels: - <code>None</code> = one coefficient for all panels - <code>&lt;panel_column_name&gt;</code> = separate coefficients by panel - <code>test</code> = GA chooses best approach Transform Whether to apply a transformation: - <code>Y</code> = use the <code>TransformType</code> defined in <code>Variable.csv</code> - <code>test</code> = GA will try different transformations TransformType One of: <code>lag</code>, <code>log</code>, <code>ma</code>, <code>adstockv3</code>, <code>abc</code>, <code>abcnew</code>, <code>adr</code>. Lag Two integers separated by <code>;</code> (e.g. <code>1;4</code> for lags 1\u20134). Scale (Optional) reserved for future use\u2014leave blank unless your process documentation specifies otherwise. Effective Two integers separated by <code>;</code> defining the \u201ceffective window\u201d length. Recency Two integers separated by <code>;</code> for the recency parameter. Decay Two decimals between 0 and 1 separated by <code>;</code> (e.g. <code>0.1;0.5</code>). Period Two integers separated by <code>;</code> for periodicity tuning. Window Two integers separated by <code>;</code> for the adstock or moving-average window. Length Two integers separated by <code>;</code> for adstock length. Peak Two integers separated by <code>;</code> for the ABC/ADR peak parameter. A Constant A for ABC/ADR\u2014always set to <code>1</code>. B Three integers separated by <code>;</code>, pre-populated using the IQR of the raw variable (e.g. <code>10;50;100</code>). C Two values between \u20135 and 0 separated by <code>;</code>, pre-populated with <code>-2;-0.5</code>. Source Populated from <code>Variable.csv</code> (e.g. <code>internal_db</code>, <code>third_party</code>). TimeUnit From <code>Variable.csv</code> (e.g. <code>week</code>, <code>month</code>). data_structure From <code>Variable.csv</code> (e.g. <code>time-series</code>, <code>cross-sectional</code>). exp_perc_contribution Two numbers between \u20131 and 1 separated by <code>;</code> (\u2013100% to +100%). Pre-populated with <code>-1;1</code> to allow full range. refresh_priors - <code>Y</code> = recompute new priors at the midpoint of <code>exp_perc_contribution</code> - <code>N</code> = use priors already defined in <code>Variable.csv</code> or your custom-priors file <p>The Scoring_Criteria sheet controls how each simulation is evaluated. By setting weights through the importance column, you can guide the GA to prioritize one or multiple performance metrics, adapting the optimization to your analysis goals. </p> <p>This makes it easy to tailor the scoring logic to different project needs\u2014whether you want to maximize model fit, enforce business constraints, or balance multiple objectives simultaneously.</p> Field Type Description Example Notes metric string The name of the metric. <code>\"R2\"</code> Not editable metric_type string A human-readable category or description of the metric. <code>\"Model fit quality (adjusted R2)\"</code> Not editable panel string Identifier for the panel or segment this metric belongs to. <code>\"region_1\"</code> Not editable threshold_min float The lower bound of the \u201cacceptable\u201d range for the metric. <code>0.9</code> Nullable; min \u2264 max threshold_max float The upper bound of the \u201cacceptable\u201d range for the metric. <code>1</code> Nullable; \u2265 min importance_raw number Raw importance score (unitless). <code>5</code> \u2265 0 importance_pct float Importance as a percentage of the total (0\u20131). <code>0.1667</code> Calculation; not editable <p>The Selection_Rules sheet is optional and helps filter out simulations that don't meet specific criteria. </p> <p>For instance, if you're testing five price variables but want the final model to include only one of them, you can use this sheet to define minimum and maximum limits for how many variables from the same group can be included. This ensures the algorithm respects structural or business constraints during optimization.</p> <p>To use this function, the user must provide:</p> <ul> <li>Basic numeric settings for the genetic algorithm (e.g., population size, generations, seed).</li> <li>Logical flags to control simulation filtering and behavior.</li> <li>Optional numeric thresholds for contribution filtering and performance.</li> </ul> <p>The function returns a list containing several elements that summarize the results of the genetic algorithm optimization.</p> <p>The <code>sim_summary</code> is a data frame that provides an overview of all simulations along with their corresponding scores, allowing users to compare overall performance. </p> <p>The <code>sim_specs</code> element is a list detailing the specific parameter configurations used in each simulation. </p> <p>For a deeper evaluation, <code>sim_scores</code> contains a data frame with more granular scoring information for each run. </p> <p>The output also includes <code>sim_priors</code>, which lists any prior constraints applied during the optimization, and <code>original_constraints</code>, a data frame capturing the initial set of modeling constraints. </p> <p>Finally, the <code>seed</code> value used during the run is returned to ensure reproducibility.</p>"},{"location":"main_documentation/#example-row","title":"Example Row","text":"Orig_Variable Variable_Group Include VaryBy Transform TransformType Lag Scale Effective Recency Decay Period Window Length Peak A B C Source TimeUnit data_structure exp_perc_contribution refresh_priors TV_Spend Media test None Y lag 1;4 1;8 0;5 0.1;0.5 1;3 1;4 1;4 2;6 1 10;50;100 -2;-0.5 Variable.csv week time-series -1;1 Y"},{"location":"main_documentation/#tips-reminders","title":"Tips &amp; Reminders","text":"<ul> <li>Semicolon (<code>;</code>) is the universal separator for all ranges.</li> <li>Scale is blank by default\u2014only populate if your workflow explicitly requires it.</li> <li>Verify that every <code>TransformType</code> you use is implemented in your GA engine.</li> <li>Double-check your <code>Variable_Group</code> names against the <code>Selection_Rules</code> tab to avoid typos.</li> <li>Use this spec as your master document; apply your corporate styles (fonts, numbering, branding) as needed.</li> </ul>"},{"location":"main_documentation/#unnesting-models","title":"Unnesting Models","text":"<p>Unnesting refers to breaking down complex models into simpler, more manageable parts. This is useful when analyzing submodels or when you want to examine the components of a hierarchical structure.</p>"},{"location":"main_documentation/#purpose-and-when-to-use","title":"Purpose and When to Use","text":"<p>Unnesting is helpful when you need to isolate the effects of individual components in a nested model.</p>"},{"location":"main_documentation/#training-materials","title":"Training Materials","text":"<p>The <code>msmp.emea</code> package provides training materials to help you get familiar with the workflow and the features of the package. These materials are automatically downloaded and set up in a dedicated folder on your machine when you run the <code>install_training()</code> function.</p>"},{"location":"main_documentation/#running-install_training","title":"Running <code>install_training()</code>","text":"<p>After installing <code>msmp.emea</code>, you can access the training materials by running the following command in your RStudio console:</p> <pre><code>msmp.emea::install_training()\n</code></pre> <p>This will create a folder containing the training materials, including documents, data files, and examples to help you practice and understand how to use the package.</p>"},{"location":"main_documentation/#training-folder-structure","title":"Training Folder Structure","text":"<p>Once you\u2019ve run the <code>install_training()</code> function, a new folder will be created with the necessary materials. This folder includes:</p> <ul> <li>Guides: Documentation and guides on the various steps involved in the MMM process.</li> <li>Data: Example datasets that you can use for practice.</li> <li>Modules: Example scripts that demonstrate the usage of <code>msmp.emea</code> functions.</li> </ul> <p>Make sure to explore these materials, as they will serve as a foundation for understanding the full capabilities of the package.</p>"},{"location":"main_documentation/#troubleshooting_1","title":"Troubleshooting","text":""},{"location":"main_documentation/#platform-specific-notes-windows-vs-macos","title":"Platform-Specific Notes (Windows vs macOS)","text":"<p>While the workflow is designed to work seamlessly on both Windows and macOS, there might be some system-specific configurations that you need to be aware of. For example, Windows users may need to include specific commands to manage file paths or dependencies. If you encounter any issues, check the documentation or reach out for support.</p>"},{"location":"main_documentation/#common-pitfalls","title":"Common Pitfalls","text":"<p>(placeholder)</p>"},{"location":"main_documentation/#reporting-issues","title":"Reporting Issues","text":"<p>If you encounter any bugs or issues with the documentation, please reach out so that we can address them in future updates.</p>"},{"location":"main_documentation/#documentation","title":"Documentation","text":"<p>For help with functions, you can use R's built-in help system. For example:</p> <p>To get detailed documentation for a function, use:</p> <pre><code>??msmp.emea::function_name\n</code></pre> <p>This will open the help page for the specified function.</p>"},{"location":"main_documentation/#final-notes","title":"Final Notes","text":"<p>(placeholder)</p>"},{"location":"main_documentation/#process-steps","title":"Process Steps","text":"<p>(placeholder)</p>"},{"location":"main_documentation/#run-model_1","title":"Run Model","text":"<p>After setting up your input files and transformations, you can run the model using the predefined functions in the package. The results will include key parameters such as coefficients for each marketing channel and insights into their effectiveness.</p>"},{"location":"main_documentation/#understanding-output","title":"Understanding Output","text":"<p>The output from the model will include detailed information on the contribution of each channel, as well as response curves that illustrate how different levels of spend impact outcomes.</p>"},{"location":"main_documentation/#response-curves_1","title":"Response Curves","text":"<p>Response curves are crucial for understanding how marketing spend translates into outcomes such as sales or revenue. These curves model diminishing returns, helping you optimize your spend by showing the point where increasing spend no longer generates proportionate returns.</p>"},{"location":"main_documentation/#fitting-abc-curves","title":"Fitting ABC Curves","text":"<p>The ABC curve is often used to model diminishing returns in marketing. By fitting this curve to the data, you can understand how increasing spend on a given marketing channel will impact the return on investment.</p>"},{"location":"main_documentation/#channel-optimization","title":"Channel Optimization","text":"<p>(placeholder)</p> <p>The <code>03_settings</code> folder, for instance, contains key files such as:</p> <ul> <li>Model Setup: Contains parameters to define the model type and analysis period.</li> <li>Variables: Lists all the variables used in your model and their corresponding transformations.</li> <li>Fit Curves: Stores the results of fitting response curves to your data.</li> </ul> <p>This structure ensures that you don\u2019t need to manually manage the files, making it easier to focus on analysis.</p>"},{"location":"main_documentation/#hd-mmm-section","title":"HD MMM Section","text":""},{"location":"main_documentation/#introduction_1","title":"Introduction","text":"<p>This document serves as a guide to help users run HD MMM projects using the <code>msmp.emea</code> package. This document and the codebase are maintained by the Annalect EMEA team, feel free to reach out to the team on any questions you have.</p> <p>The flowchart below outlines a high level overview of how a HD project will look like.</p> <p></p>"},{"location":"main_documentation/#pre-requisites","title":"Pre-requisites","text":"<p>Before going into the project setup, there are a few pre-requisites that we would like to outline:</p> <ol> <li> <p>Have the latest package version of <code>msmp.emea</code> installed. Link to the repo can be found here: msmp.emea</p> </li> <li> <p>An MMM model. HD is a build on top of MMM so it requires an already established MMM model. Do note that the codebase requires the user to create the MMM models within the <code>msmp.emea</code> environment. If your MMM models are built using another solution, do reach out to a member of the team to discuss the best way forward.</p> </li> <li> <p>Media data splits. Having good data is central to a HD model's success. HD integrates this information by incorporating two additional files on top of the already established MMM model - HD template and HD meta files (See examples below). Both files can be created from the media data using the <code>msmp.emea::process_hd_data()</code> function within the package.</p> </li> </ol>  Example of a HD template table  Example of a HD meta table  Orig_Variable Next_Level_Down tv_grps tv_tactical_grps tv_grps tv_brand_grps tv_grps tv_tactical_puba_grps tv_tactical_grps tv_tactical_pubb_grps tv_tactical_grps tv_brand_pubb_grps tv_brand_grps tv_brand_pubc_grps tv_brand_grps Orig_Variable Group1 Group2 Group3 tv_tactical_puba_grps TV Tactical PubA tv_tactical_pubb_grps TV Tactical PubA tv_brand_pubb_grps TV Brand PubB tv_brand_pubc_grps TV Brand PubC"},{"location":"main_documentation/#project-setup","title":"Project Setup","text":"<p>In this section, we will walk through the setup of a HD model using the RMarkdown template in detail. This guide will cover each step in the Rmd template and explain what it is trying to achieve.</p> <ol> <li> <p>Initial HD project setup</p> <ol> <li>Intialise the Rmd file<ul> <li>With the <code>msmp.emea</code> package installed, you should be able to see a HD MMM RMarkdown template. Initialise this file within your project folder. Save this file in the same location as your MMM model Rmd. You can create a template from RStudio by following the instruction below.</li> <li> <p>File -&gt; New File -&gt; R Markdown... -&gt; From Template -&gt; HD-mmm -&gt; Ok</p> </li> </ul> </li> <li> <p>Define Yaml Parameters</p> <ul> <li>Start by defining Yaml parameters at the top of the file. Ensure all parameters are accurate, particularly <code>mmm_model_id</code>, which must match the corresponding entry in the <code>table_of_model_ids.csv</code></li> <li> <pre><code>---\ntitle: \"Project Title\"\nauthor: \"Your name\"\ndate: \"Date\"\nparams:\n  model_client: \"client_name\"\n  model_product: \"product1\"\n  model_region: \"country\" \n  model_year: \"2023\"\n  model_version: \"1.0\"\n  model_kpi: \"my_kpi\"\n  model_panel: FALSE\n  mmm_model_id: \"Your MMM model ID\"\n  hd_model_version: \"v_1.0\"\n---\n</code></pre> </li> </ul> </li> <li> <p>Set Date Ranges</p> <ul> <li>Define the transform and modelling date ranges of your HD model. These date ranges will need to be the same as your MMM model as HD is very sensitive to this.</li> <li>For example, you can have a case where your transform start date is a month earlier than your actual model start date to take into account for media adstocks.</li> </ul> </li> </ol> </li> <li> <p>Setting Up and Loading in Data</p> <ol> <li> <p>Run Initialization</p> <ul> <li>Execute the <code>hd_mmm_init()</code> function to generate the folder structure required for the project.</li> <li>Based on the parameters in the Yaml file, it will create a folder called <code>07_hd_mmm</code> at <code>{model_client}_{model_year}/{model_region}_{model_product}_{model_kpi}/{model_version}</code></li> </ul> </li> <li> <p>Populate the required files for the project</p> <ul> <li>HD Variables: The <code>07_hd_mmm/01_hd_settings/01_input_hd_variables</code> folder will be auto-populated with the Variables.csv file from the MMM model output folder. The user need only check the csv file such that all HD media variables have the labels at \"AggregateVariable\" column set to \"Media\" and \"Simulate\" column set to \"Y\".</li> <li>HD Template: User will need to copy the hd template csv file into the folder <code>07_hd_mmm/01_hd_settings/02_input_hd_template</code>. </li> <li>HD Meta: User will need to copy the hd meta csv file into the folder <code>07_hd_mmm/01_hd_settings/03_input_meta</code>. </li> <li>HD Data (Optional): If HD level data is already supplied at the MMM stage, there is nothing to do here. Otherwise, user will need to populate the folder <code>07_hd_mmm/01_hd_settings/04_input_hd_data</code> with the relevant csv files.</li> </ul> </li> <li> <p>Re-run the initialisation function</p> <ul> <li>Once the previous step has been completed. Re-run the <code>hd_mmm_init()</code> function.</li> <li>If successful, you should be able to see 3 new files in the <code>07_hd_mmm/01_hd_settings</code> folder.<ul> <li><code>{mmm_model_id}_HDModObj.RData</code>: A copy of your model object</li> <li><code>{mmm_model_id}_HDVariables.csv</code>: HD variables csv file, it contains all the information on variables in the model and any HD level variables</li> <li><code>{mmm_model_id}_Meta.csv</code>: HD meta file</li> </ul> </li> </ul> </li> </ol> </li> <li> <p>Setup HD Variables, Meta and Weights file</p> <ol> <li> <p>At this stage, we should already have most of the HD files setup. The crucial step in this chunk is to make sure that the <code>PreWeights</code> for each HD variables are populated correctly. To facilitate this, user should use the <code>update_hd_preweights()</code> function to update the preweights accordingly. For any media variables that cannot be auto-populated by the function, the user can use the <code>vars</code> and <code>preweights</code> argument to populate them manually.</p> </li> <li> <p>The key thing to keep in mind is that all HD media variables should be in the same scale (i.e. all HD variables are impressions metric or all are in clicks metrics or roughly in the same ballpark in terms of representative size) due to the weight optimization algorithm which rescales these variables.</p> </li> <li> <p>If this chunk ran successfully, you should be able to see a new file in the <code>07_hd_mmm/01_hd_settings</code> folder.</p> <ul> <li><code>{mmm_model_id}_Weights.csv</code>: HD weights file, this file is where user will provide information on the HD weights (This file will open once the chunk runs successfully)</li> </ul> </li> <li> <p>Next step for the user will be to update the Weights file</p> <ul> <li>User will need to update the <code>Lower_Weight</code> and <code>Upper_Weight</code> columns which corresponds to your HD variables. A common initial bounds to use is [0.7,1.3]. (An example is shown below)</li> <li> <p>Here is a brief explanation of what each column of the file means:</p> <ul> <li>Group &amp; Value: These column corresponds to the group and group names of all variables from the meta file. <code>Group1</code> corresponds to your MMM level variables whereas the subsequent groups <code>Group2</code>, <code>Group3</code>, etc. corresponds to the HD level groupings.</li> <li>Weight: Weight assigned to the group, bigger number means bigger importance. All weights are initialised to be 1. Weight of 1s for all groups will give you the same results as your MMM model.</li> <li>Lower_Weight &amp; Upper_Weight: Lower and upper bound of the weights that you allow the algorithm to explore. You should only set Lower and Upper weights for HD groups, i.e. all <code>Group1</code>, <code>Intercept</code>, <code>Dependent</code>, and <code>Base</code> values should be fixed at 1.</li> <li>Uncontrolled_Weight: You can ignore this column as this will be populated when we run the weights optimization algorithm.</li> <li>Example of a weights table:</li> </ul> Group Value Weight Lower_Weight Upper_Weight Uncontrolled_Weight Group1 Intercept1 1 1 1 1 Group1 Base1 1 1 1 1 Group1 Dependent1 1 1 1 1 Group1 Display 1 1 1 1 Group1 YouTube 1 1 1 1 Group2 Direct 1 0.7 1.3 1 Group2 Programmatic 1 0.7 1.3 1 Group3 Home 1 0.7 1.3 1 Group3 Technology 1 0.7 1.3 1 Group3 Fashion 1 0.7 1.3 1 </li> </ul> </li> </ol> </li> <li> <p>Update the weights file and run a series of pre-transformation checks</p> <ol> <li>In this chunk, the functions will run a series of checks on the HD spec and control files (meta and weights file) to detect any errors or flag any warnings.</li> </ol> </li> <li> <p>Run Checks and Create Variable Transformations + Weightings for HD MMM</p> <ol> <li>At this stage we are almost done with the HD setups and will be able to run the optimization algorithm soon. One last step that we need to do is to check whether we are able to recreate the MMM model outputs from our HD setup. This is an important step as it gives us confidence that we have set HD up for success.</li> <li>Let's go through some of the key functions in this chunk:<ul> <li><code>HD_Variable_Tranformations()</code>: HD version of Transform()</li> <li><code>Distribute_Weights()</code>: Apply weights from the weights file to the HD variables. At this stage all weights should be 1 (Unless the user has provided a different set of weights to initalise HD)</li> <li><code>Measures_of_Extreme_Transformations()</code>: Gives information on how shape of the adstocks and diminishing returns transformations. An example is shown below               Example for adstock extremity.                       Example for DR extremity.          </li> <li><code>hd_update_priors()</code>: Updates the priors of the model as the HD variables are in a different scale from the MMM model</li> <li><code>Decomposition_Levels()</code>: HD version of Decomp()</li> </ul> </li> <li>This chunk should run fine without needing any edits to the code. Once the chunk runs, it should create two comparison tables - a decomposition table comparison and a coefficients table comparison.<ul> <li>Decompoistion table comparison: This is what is important. We should see minimal differences between the two decomps.</li> <li>Coefficient table comparison: We can see that the HD model's coefficients for media variables look different from their MMM counterpart. This is because of the scaling that is applied to those variables which will be important in the optimization algorithm.</li> </ul> </li> </ol> </li> <li> <p>Weights Optimization     There are two stages when it comes to optimization of HD weights. First, the algorithm will search for the best possible weights within the bounds specified. After that, a fine tuning algorithm will be run to penalize weights that are not contributing significantly. The idea behind penalizing weights is similar to that of a Lasso or Ridge regression. Similar to how a penalized coefficient will be pulled towards 0, in this case, a penalized weight will be pulled back towards 1. We have broken down this stage into 3 sections: (1) Establishing a rough range the optimal penalty might sit in, (2) Do a grid search of the penalty range, (3) Run the optimization algorithm with the optimal penalty value</p> <ol> <li> <p>Uncontrolled weights and penalty range</p> <ul> <li>In this chunk, we are looking to understand the range of penalty values that we should test for the model. When we run the optimization algorithm with <code>UCOpt</code> set to TRUE, we can see a suggested penalty range printed in the console.</li> </ul> <pre><code>Set the penalty for optimization somewhere between 65.2 and 2693.4 for this data.\n  With a penalty of 271.9 preventing only the worst over-fitting but has very high R-Squared.\n  A penalty of 753.8 a good average amount of control.\n  And a penalty of 936.5 allows only the most statistically significant weights. \n</code></pre> <ul> <li>Besides that, the uncontrolled weights will also give us an idea of whether the bounds we set for our groups are sufficient. For example, if the uncontrolled weight of a group goes beyond its upper or lower bound, it is advised to widen the bound.<ol> <li>Testing penalty values</li> </ol> </li> <li>Once we have the initial penalty values that we can be testing, we can input them into the <code>penalty_vals</code> vector and run the chunk to test out these values. The chunk willl take a while to run, and once finished, it will create a folder called <code>hd_penalty_loop_outputs</code> in the main folder and output the results in an excel file. We will talk more about analysing this output in the next section.</li> <li>This is an iterative process, which means we will need to run this chunk multiple times until we find a good penalty value that works well with the model. For example, I have tested penalty values [10, 20, 50, 75, 100] and have found that 20 seems to be giving me the most optimal result. Next, I will test the penalty values [15, 18, 21, 25, 30] to determine which values in the vicinity of 20 gives me a better result. As you can see, it can take quite a few tries to get to our final penalty value.</li> <li>Do note that optimal penalty value may vary from one group to another, so it is important to balance this as we can only have one penalty value in the end.<ol> <li>Run optimization with optimal penalty value</li> </ol> </li> <li>After testing all the penalty values and have found the one that is suitable for our model, input that value into the weights optimization function to create our final output.</li> <li>With this, we should have everything we need - Final HD Weights, HD Decomp table, and HD Response Curves. All that we need to do now is save the output.</li> </ul> </li> </ol> </li> </ol>"},{"location":"main_documentation/#analyzing-hd-outputs","title":"Analyzing HD Outputs","text":"<p>This section aims to breakdown the excel file output generated from the penalties testing stage. In the file, you will see 4 sheets:</p> <ol> <li> <p>RanWeights</p> <ul> <li>As you can see, this sheet resembles the weights file quite a bit, with a few additional columns. It displays the random weights that we get from the optimization algorithm. If you recall, the optimization algorithm runs in two stages, it first gets the best weight in the range, then it refines the weights using the penalty value. Random weights are the weights we get from the first stage of the optimization (best weights in the range). Therefore, these weights are optimized without the use of penalty values. You can think of these weights as weights we get from a penalty of 0.</li> <li>Purpose: To understand whether the algorithm is giving us consistent results across each run. This is very important as it tells us that the algorithm has converged. However, when we see inconsistencies between runs, the user have to dive into why this is the case. There are a few explanation as to why the weights may not have converged:<ul> <li>Size of the group is too small (inidicated by the size column). When the size is too small, the choice of giving it a weight close to the upper bound or the lower bound yields insignificant change to the model. In this case, user can choose not to weight them at all (set lower and upper bounds to 1).</li> <li>Run time is too short. When the search range is large or there are many groups in a level, the search space is big and the algorithm hasn't had the chance to explore a good chunk of the parameter space. In this case, it will be wise to increase the run time.</li> <li>In cases where the groups are very big and relationship between groups are complex. It is sufficient to observe whether the weights are telling a consistent story, e.g. Group X in Level 2 consistently outperforms the other groups in the same level although it takes on different values in each run.</li> </ul> </li> </ul> </li> <li> <p>Weights</p> <ul> <li>This sheet is very similar to the RanWeights sheet, with a slight difference whereby instead of random weights, these weights are the fine tuned version of random weights (weights we get from the second stage of the optimization algorithm). Therefore, these weights are heavily influenced by the penalty values.</li> <li>Purpose: Look for consistencies across different runs within the same penalty value. Choosing the best penalty value will be up to the analyst's judgement. However, do keep in mind that the weights should be reasonable and tell us a meaningful story. (e.g., A set of weights of 1s as our output isn't telling us anything new as these are the default results we get from our MMM model)</li> </ul> </li> <li> <p>Effect</p> <ul> <li>You can think of effect as a value showing how significant the group is at increasing the model's performance when it's weight is increased/ decreased by a small step in either direction. The bigger the value, the more significant the group is.</li> </ul> </li> <li> <p>Decomp</p> <ul> <li>As looking at the decomposition table is an important factor while deciding on penalty values, its corresponding decomp table of each weights optimization run is saved here so the user can always refer to it when needed.</li> </ul> </li> </ol>"},{"location":"mmm/","title":"MMM Workflow","text":"<p>In this section, we will go through a typical MMM workflow (as outlined in our predefined Rmd template). Through this, you will get a few key results: model statistics, decomposition tables, and media response curves.</p>"},{"location":"mmm/#load-and-clean-data","title":"Load and clean data","text":"<p>In this step, raw data sources (media, sales, promotions, seasonality, etc.) are loaded and pre-processed. You\u2019ll standardize column formats, handle missing values, align time series, and possibly merge disparate datasets to create a unified modeling dataset.</p>"},{"location":"mmm/#model-object","title":"Model object","text":"<p>You create the base model object using the <code>msmp.emea</code> functions. This object acts as the container for all subsequent modeling steps and configurations. It typically includes raw input data, metadata, and placeholder slots for transformed data, priors, and model outputs.</p>"},{"location":"mmm/#model-setup","title":"Model setup","text":"<p>Here, you define modeling parameters such as the dependent variable (target), media channels, control variables, time windows, and holiday effects. This is where the modeling framework is initialized \u2014 effectively \u201ctelling\u201d the model what to expect.</p>"},{"location":"mmm/#model-specification","title":"Model specification","text":"<p>Also referred to as \"model spec,\" this step involves defining how variables enter the model: what transformations are applied (e.g., adstock, saturation), which priors are used in Bayesian estimation, and whether interactions or groupings are introduced. It\u2019s a critical step that shapes the econometric assumptions.</p>"},{"location":"mmm/#data-transformation-and-validation","title":"Data Transformation and Validation","text":"<p>At this stage, data is transformed according to the model spec: media variables may be adstocked, logged, or saturated. You also perform validation checks to ensure data aligns with model assumptions (e.g., no missing data, consistent timeframes).</p>"},{"location":"mmm/#run-model","title":"Run Model","text":"<p>You fit the model using the inference engine provided in <code>msmp.emea</code>. This step will also provide diagnostics for results inspection. You may iterate multiple times, adjusting specifications or priors based on initial results.</p>"},{"location":"mmm/#decomposition","title":"Decomposition","text":"<p>Here you decompose the predicted values into contributions from each variable or group of variables (e.g., media, price, promotions). This allows you to understand what\u2019s driving performance and quantify the ROI of each input.</p>"},{"location":"mmm/#response-curves","title":"Response Curves","text":"<p>Response curves (a.k.a. saturation curves) show how the output responds to incremental changes in each media variable. These are essential for budget planning and optimization, helping identify diminishing returns and efficient spend thresholds.</p>"},{"location":"mmm/#supported-transformations","title":"Supported Transformations","text":"<p>The <code>msmp.emea</code> package supports several transformations to handle data in ways that optimize the MMM process. Some of the key transformation types are:</p> TransformType Caller Explanation adstockv3 Adstock Applies a standard adstock transformation to model lagged and decaying media effects. adstockv4imp Adstock with rescaled impressions Similar to standard adstock but used for impression data, applying rescaling to account for volume. adr Ad response Applies an advertising response function, typically used for modeling non-linear saturation effects. lag Lag Shifts the variable backward in time to capture delayed effects. log Log Applies a logarithmic transformation to reduce skew and stabilize variance. ma Moving average Smooths the variable by averaging over a specified time window to reduce noise. abcnew For diminishing returns Applies a functional form tailored for diminishing returns (e.g., sigmoid or Hill-type curves). none No transformation Leaves the variable untransformed. Use when no preprocessing is required. customt() Custom transformation Applies a user-defined transformation using a formula-like string. For example, customt(\"x^2\") squares the input.\" boxcox Boxcox Applies a Box-Cox transformation to stabilize variance and approximate normality. <p>The <code>Transform</code> function allows you to apply multiple transformations by chaining them together using underscores (_). Each TransformType will be applied in the order specified, from left to right.</p>"},{"location":"mmm/#final-notes","title":"Final Notes","text":"<p>(placeholder)</p>"},{"location":"mmm/#process-steps","title":"Process Steps","text":"<p>(placeholder)</p>"},{"location":"mmm/#run-model_1","title":"Run Model","text":"<p>After setting up your input files and transformations, you can run the model using the predefined functions in the package. The results will include key parameters such as coefficients for each marketing channel and insights into their effectiveness.</p>"},{"location":"mmm/#understanding-output","title":"Understanding Output","text":"<p>The output from the model will include detailed information on the contribution of each channel, as well as response curves that illustrate how different levels of spend impact outcomes.</p>"},{"location":"mmm/#response-curves_1","title":"Response Curves","text":"<p>Response curves are crucial for understanding how marketing spend translates into outcomes such as sales or revenue. These curves model diminishing returns, helping you optimize your spend by showing the point where increasing spend no longer generates proportionate returns.</p>"},{"location":"mmm/#fitting-abc-curves","title":"Fitting ABC Curves","text":"<p>The ABC curve is often used to model diminishing returns in marketing. By fitting this curve to the data, you can understand how increasing spend on a given marketing channel will impact the return on investment.</p>"},{"location":"mmm/#channel-optimization","title":"Channel Optimization","text":"<p>(placeholder)</p> <p>The <code>03_settings</code> folder, for instance, contains key files such as:</p> <ul> <li>Model Setup: Contains parameters to define the model type and analysis period.</li> <li>Variables: Lists all the variables used in your model and their corresponding transformations.</li> <li>Fit Curves: Stores the results of fitting response curves to your data.</li> </ul> <p>This structure ensures that you don\u2019t need to manually manage the files, making it easier to focus on analysis.</p>"},{"location":"modeling-overview/","title":"Modeling Overview","text":"<p>Our workflows are designed to ensure consistency, transparency, and reproducibility across projects.</p> <p>The <code>msmp.emea</code> package supports two distinct yet complementary approaches for analyzing media effectiveness: a Bayesian Marketing Mix Modeling (Bayesian MMM) approach and a more granular High-Definition (HD) modeling approach. Both share a common foundation but are designed to answer different types of business questions.</p>"},{"location":"modeling-overview/#overview-of-modeling-approaches","title":"Overview of Modeling Approaches","text":"Bayesian MMMHigh-Definition (HD) Modeling <p>The Bayesian MMM approach is a modern version of the classical Marketing Mix Modeling framework, implemented using Bayesian inference. This method enables the quantification of media effectiveness and ROI while explicitly accounting for uncertainty in parameter estimates.</p> <p>Key characteristics of the Bayesian MMM approach:</p> <ul> <li>Prior knowledge incorporation: Prior distributions can be used to incorporate historical learnings or domain expertise into the model.</li> <li>Flexibility: The Bayesian framework supports complex modeling features such as hierarchical structures, seasonality components, and non-linear saturation effects.</li> </ul> <p>This approach is ideal when the goal is to build robust, interpretable models with quantified uncertainty and leverage prior knowledge to stabilize estimates in data-scarce environments.</p> <p>HD MMM is a build on top of the current MMM toolkit where you would be able to take a more detailed look into the contributions of your total media channel. For example, two main strategies were used for a digital channel - strategy A and strategy B. </p> <p>The HD algorithm will then be able to approximate the effectiveness of each strategy based on the flighting pattern and give you a breakdown of each strategy's contribution that makes up the total digital channel's contribution in the MMM model.</p>"},{"location":"modeling-overview/#workflow","title":"Workflow","text":"Bayesian MMMHigh-Definition (HD) Modeling"},{"location":"modeling-overview/#workflow-templates","title":"Workflow Templates","text":"<p>The <code>msmp.emea</code> package includes a set of predefined workflow templates designed to guide you through the media modeling process. These templates are accessible directly from RStudio, helping ensure a standardized, efficient, and reproducible workflow.</p>"},{"location":"modeling-overview/#available-templates","title":"Available Templates","text":"<ul> <li>Model-Workflow: A standard template for running a complete MMM analysis.</li> <li>HD-MMM: A template for Hierarchical Decomposition modeling, enabling granular analysis within channels.</li> <li>Unnest-Models: A utility template for unnesting models and analyzing their individual components.</li> </ul> <p>These templates streamline your workflow by reducing setup time, minimizing the risk of error, and ensuring all critical steps are included.</p>"},{"location":"modeling-overview/#how-to-use-templates-in-rstudio","title":"How to Use Templates in RStudio","text":"<p>To launch a template in RStudio:</p> <ul> <li>Click on the New File icon.</li> <li>Select R Markdown.</li> <li>Choose From Template, then pick the relevant <code>msmp.emea</code> template.</li> </ul> <p>RStudio will create a new document pre-filled with the appropriate structure, guidance, and placeholders to help you get started quickly.</p>"},{"location":"project-setup/","title":"Project Setup","text":"<p>This section will touch on two key components of the package: folder setup and data structure of a typical MMM project. Understanding the folder structure will help users understand better on where certain model parameters and data are ingested, and where the results from the MMM models can be found, allowing users to be more efficient in working with the package. In the data structure section, we will talk about how the data for an MMM project should be structured. Having a standardised approach to the data structure will decrease unnecessary errors significantly.</p>"},{"location":"project-setup/#folders-setup","title":"Folders Setup","text":"<p>This is the initial phase where (in your workflow template) you define the modeling scope, select the business KPIs (e.g., revenue, conversions), and determine the modeling granularity (e.g., weekly, country-level). The workflow will guide you to create a project folder structure and set configuration files or paths for your inputs and outputs.</p> <p>Once you run the <code>project_init()</code> function, a new folder structure will be created on your machine. This structure is designed to help organize your data and outputs so that the package can easily access the files it needs to run the analysis.</p>"},{"location":"project-setup/#folders-and-file-overview","title":"Folders and File Overview","text":"<p>The following files and folders are automatically created by the package during project initialization. They provide a standardized structure to support a smooth and reproducible modeling workflow.</p> <p></p> 01_data02_eda03_model_workflow04_model_settings 05_model_output06_documentationmodel_id.txt <p>This folder contains all raw and pre-processed input data used in the modeling process. This may include media spend, sales or conversions, control variables (e.g., pricing, promo), seasonal flags, and any other relevant time-series data. Ideally, files here are versioned and read-only, ensuring consistency across runs.</p> <p>The Exploratory Data Analysis (EDA) folder holds visualizations, summary statistics, and diagnostics used to understand and validate the input data before modeling.</p> <p>Note: this feature is still under development</p> <p>This folder contains a copy of the main R markdowns that run the modeling pipeline. These scripts handle tasks such as initializing the model object, setting up the model, transforming variables, running the estimation, and generating outputs. Think of this as the \"engine room\" of your workflow.</p> <p>This folder stores configuration files (mostly .CSV) that define model inputs and hyperparameters. These settings include which variables are included, prior distributions, transformation settings (e.g., adstock, saturation), and modeling time windows. </p> <p>This folder captures all outputs generated by the model, such as contribution decompositions, model diagnostics, or a copy of the model object. It may also include visual reports or summary tables. Outputs here are often used to support stakeholder decision-making.</p> <p>This folder is created for the users to store documentation about the project: modeling rationale, decisions, assumptions, meeting notes, and final deliverables. It might also contain markdown files, slide decks, or PDFs that explain the project flow, outcomes, and business recommendations.</p> <p>This file contains a unique identifier for the model run. It helps track and reference a specific set of modeling configurations, inputs, and outputs, especially in workflows that involve multiple iterations or parallel experiments.</p> <p>The <code>model_id.txt</code> file typically includes a short string that is automatically generated by the pipeline.</p> <p>Why it's important:</p> <ul> <li>Ensures traceability between model inputs and outputs.</li> <li>Allows consistent naming of output files.</li> <li>Makes collaboration easier by giving analysts a common reference point.</li> </ul> <p>Typical usage in the pipeline:</p> <ul> <li>Read in during model initialization to tag outputs.</li> <li>Stored alongside outputs and logs.</li> </ul>"},{"location":"project-setup/#input-files","title":"Input Files","text":"<p>These are the key files you'll interact with throughout the modeling phase. They form the foundation of the workflow, guiding what data will be transformed, analyzed, and ultimately modeled.</p> Model Setup FileVariables File <p>The Model Setup file is the first configuration you'll edit when starting your analysis. It defines key parameters that control how the model is structured and what data is used. These settings guide both model estimation and response curve analysis.</p> <p>This file is essential for configuring your analysis and should be carefully reviewed and updated before running any model.</p> Parameter Explanation Mandatory_Field ModelForm Specifies the regression model form. Options include 'lin_lin' (linear), 'log_lin' (log-transformed response), and 'mc_lin' (mean-centered transformed response). Yes Panel Indicates whether the model supports panel data structure. Set to 'Y' to ensure compatibility, even for non-panel use cases. Yes Time Name of the time-related column in the dataset, typically representing months or weeks. Yes Geo Not currently in use. No CS Defines the main cross-sectional unit used in panel models (e.g., product, market, or vehicle). Yes CS2 Optional second-level cross-sectional identifier (not currently available) No BeginDate Start date for the analysis period. Format should be DD/MM/YYYY. Yes EndDate End date for the analysis period. Format should be DD/MM/YYYY. Yes numSubModel Optional. Specifies how many sub-models are linked to the main model. No Submodel_Link1 Name of the parent variable in the main model used to link to the first sub-model. No Submodel_Link2 Name of the parent variable used to link to the second sub-model. No Submodel_Link3 Name of the parent variable used to link to the third sub-model. No subModel1 Name or label of the first child sub-model to be used in hierarchical modeling. No subModel2 Name or label of the second child sub-model to be used in hierarchical modeling. No subModel3 Name or label of the third child sub-model to be used in hierarchical modeling. No SimStart Start date for the simulation period used in response curve generation. Format: DD/MM/YYYY. Yes SimEnd End date for the simulation period used in response curve generation. Format: DD/MM/YYYY. Yes Mroi Increment size used to simulate changes in media investment when generating response curves. Yes <p>The Variables file defines all variables used in the model along with their inclusion status and transformation settings. This file gives you full control over how each variable is treated in the modeling pipeline.</p> <p>This file is critical for customizing model inputs and ensuring each variable is preprocessed appropriately for the analysis.</p> Column_Name Explanation Workflow_Component Orig_Variable Original name of the variable as it appears in the raw dataset All functions Trans_Variable Name to use for the variable after any transformation All functions AggregateVariable Indicates a grouping variable for aggregating similar sub-variables Decomposition Variable_Type Specifies the type of variable (e.g., Dependent, Trend, Default) Decomposition Include Binary flag (1/0) indicating if the variable should be included in the model All functions VaryBy Specifies if the variable coefficient varies by a grouping (only for panel data) Coefficients estimation Transform Whether the variable should be transformed (Y/N) - Keep this as default. Transformation TransformType Type of transformation (e.g., adstock, log, lag, saturation) Transformation Lag Number of periods to lag the variable Transformation Scale Scaling factor to adjust the variable values Transformation Effective Ad Response transformation (tbd) Transformation Recency Ad Response transformation (tbd) Transformation Decay Decay rate for adstock or adr (value between 0 and 1; a higher value means faster decay). Transformation Period Ad Response transformation (tbd) Transformation Window Size of the moving window (e.g., for rolling averages) Transformation Trim Currently not in use Transformation Length Maximum number of time periods over which advertising memory can persist. Transformation Peak Indicates the peak point in a adstock transformation. Transformation AT_Divisor Arc-Tangent parameter (rarely used) Transform (for diminising returns) NE_Divisor Negative Exponential parameter (rarely used) Transform (for diminising returns) A Ceiling of ABC curve (keep as 1) Transform (for diminising returns) B Parameter of ABC curve (typically set between 20\u201380% of the variable\u2019s maximum value.) Transform (for diminising returns) C Parameter of ABC curve (If c &gt; -1, the function is logarithmic; if c &lt; -1, the function follows an S-shaped curve). Transform (for diminising returns) Max_Grps Not in use Transformation Prior_Mean Prior mean for Bayesian estimation Coefficients estimation Prior_SD Prior standard deviation for Bayesian estimation Coefficients estimation PriorSD_Adj Adjustment factor for prior standard deviation Coefficients estimation Sign Not in use nan Override Not in use nan Simulate Indicates if the variable is used for response curves Response Curve RC_Shape Defines the shape of the response curve for the variable Response Curve Explore_correlation Whether to include the variable in correlation diagnostics EDA Explore_transformation Whether to explore alternate transformations during modeling EDA Spent_Variable Reference to the spend version of the variable (if separated from exposure) Response Curve Cost_per_unit Unit cost of the media (used in efficiency calculations) Response Curve Source Metadata field indicating where the variable came from Transformation TimeUnit Time granularity of the variable (e.g., weekly, monthly) Transformation"},{"location":"project-setup/#data-structure","title":"Data Structure","text":"<p>Before diving into model workflow, it's important to clarify how data should be structured, as this affects how the package processes inputs and ensures consistent behavior across different types of datasets \u2014 whether panel or non-panel.</p>"},{"location":"project-setup/#panel-vs-non-panel-data","title":"Panel vs. Non-Panel Data","text":"<p>In the context of Marketing Mix Modeling (MMM), panel data refers to datasets that contain observations across multiple units (such as regions, brands, or stores) over time. Each unit has its own time series, allowing analysts to capture both temporal dynamics and cross-sectional variation.  This can improve model robustness by leveraging patterns across similar entities and supporting more generalizable insights.</p> <p>By contrast, non-panel data (also known as time series or aggregate data) includes a single stream of observations over time, typically representing national-level performance or a single entity. </p> <p>While simpler to manage, non-panel data limits the ability to control for unit-specific effects and can lead to more fragile estimates if the dataset is small or noisy.</p> Date Car Model Orders TV Spend Radio Spend 2022-01-01 Alpha 91 872.13 2916.01 2022-01-01 Beta 154 2412.97 3266.66 2022-01-01 Delta 115 3973.21 1752.63 2022-01-01 Gamma 96 175.27 4847.49 2022-01-08 Alpha 71 7417.53 3864.92 2022-01-08 Beta 151 1462.11 1039.69 2022-01-08 Delta 165 3163.78 3402.06 2022-01-08 Gamma 78 9267.57 2904.78 2022-01-15 Alpha 107 9244.82 2923.08 2022-01-15 Beta 91 2707.85 4926.91 <p> Note: Car Model is the panel identifier used to group data by vehicle type. </p>"},{"location":"project-setup/#why-use-a-panel-format","title":"Why Use a Panel Format","text":"<p>Our modeling approach standardizes how data is treated by assuming a panel structure for all input datasets. This provides consistency in how models are built, regardless of the original data format. </p> <p>If a dataset is not naturally a panel (i.e., it contains only a single time series), we automatically add a grouping column to create a \"panel of one\". This ensures that all processing and modeling routines \u2014 such as decomposition, contribution analysis, and cross-validation \u2014 can be applied uniformly, without needing special handling for different data types.</p> Date Panel Col Orders TV Spend Radio Spend 2022-01-01 client_name 151 3550.62 4911.53 2022-01-08 client_name 129 5245.67 2383.74 2022-01-15 client_name 103 9522.32 1516.49 2022-01-22 client_name 151 7284.52 4516.02 2022-01-29 client_name 150 6993.12 4187.69 2022-02-05 client_name 111 5301.55 1624.52 2022-02-12 client_name 125 8073.22 4493.61 2022-02-19 client_name 155 2835.41 1832.87 2022-02-26 client_name 109 8590.96 4512.57 2022-03-04 client_name 143 826.44 2390.48 <p> Note: Panel Col identifies groups when panel structure is required. If the data isn't in panel format, this will be generated automatically. </p>"},{"location":"project-setup/#advantages-of-a-unified-approach","title":"Advantages of a Unified Approach","text":"<p>Treating all datasets as panels simplifies the architecture and improves model scalability. It allows us to apply the same logic for feature engineering, constraints, and optimization routines \u2014 whether the user provides a multi-brand dataset or a single-country time series. </p> <p>This also makes it easier to expand to true panel use cases in the future, as the underlying structure already supports multiple groups.</p>"},{"location":"training/","title":"Training Materials","text":"<p>The <code>msmp.emea</code> package provides training materials to help you get familiar with the workflow and the features of the package. These materials are automatically downloaded and set up in a dedicated folder on your machine when you run the <code>install_training()</code> function.</p>"},{"location":"training/#running-install_training","title":"Running <code>install_training()</code>","text":"<p>After installing <code>msmp.emea</code>, you can access the training materials by running the following command in your RStudio console:</p> <pre><code>msmp.emea::install_training()\n</code></pre> <p>This will create a folder containing the training materials, including documents, data files, and examples to help you practice and understand how to use the package.</p>"},{"location":"training/#training-folder-structure","title":"Training Folder Structure","text":"<p>Once you\u2019ve run the <code>install_training()</code> function, a new folder will be created with the necessary materials. This folder includes:</p> <ul> <li>Guides: Documentation and guides on the various steps involved in the MMM process.</li> <li>Data: Example datasets that you can use for practice.</li> <li>Modules: Example scripts that demonstrate the usage of <code>msmp.emea</code> functions.</li> </ul> <p>Make sure to explore these materials, as they will serve as a foundation for understanding the full capabilities of the package.</p>"}]}